{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a32dd4-4958-4e6c-bb62-b8012f4c08f5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5934ba-a717-4804-977c-8aa7862fb426",
   "metadata": {},
   "source": [
    "### Import modules and initialize parameters for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09d5ee-10b9-4366-b53b-dba1369dc11d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker import get_execution_role, image_uris\n",
    "import time\n",
    "import logging\n",
    "import boto3\n",
    "import os\n",
    "import json\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8c3163-e7d0-40f1-941e-baf1530512fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "region_name = sagemaker.Session().boto_region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4a25ea-9d62-42f6-990b-5c3a9e9ebb26",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize bucket names and load models\n",
    "*default_bucket* is the name of the bucket where the data is stored. Requires read permissions.\n",
    "\n",
    "*output_bucket* is the name of the bucket where the model will be stored after training. Requires read/write permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e415300-9a77-4160-925f-f9d811f6e7d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# default_bucket = \"summer-team-bucket\"\n",
    "# output_bucket = \"summer-team-bucket\"\n",
    "default_bucket = sess.default_bucket()\n",
    "output_bucket = default_bucket\n",
    "base_job_prefix = \"cloudd-rf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda2d144-b41c-481b-a642-52cdba4a0881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ../code/team1_model.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Team1Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(2, 16))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=(1, 8))\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(1, 8))\n",
    "        #self.fc1 = nn.Linear(in_features=15360, out_features=1200)  # Fully Connected Layer\n",
    "        self.fc1 = nn.LazyLinear(out_features=1200)\n",
    "        self.fc2 = nn.Linear(in_features=1200, out_features=100)\n",
    "        self.fc3 = nn.Linear(in_features=100, out_features=65)\n",
    "        self.fc4 = nn.Linear(in_features=65, out_features=self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # print(f'after conv1: {x.shape}')\n",
    "        x = self.pool(x)\n",
    "        # print(f'after pool: {x.shape}')\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # print(f'after conv2: {x.shape}')\n",
    "        x = self.pool(x)\n",
    "        # print(f'after pool: {x.shape}')\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # print(f'after conv3: {x.shape}')\n",
    "        x = self.pool(x)\n",
    "        # print(f'after pool: {x.shape}')\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        # print(f'after reshaping: {x.shape}')\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # print(f'fc1: {x.shape}')\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # print(f'fc2: {x.shape}')\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # print(f'fc3: {x.shape}')\n",
    "        #x = F.relu(self.fc4(x))\n",
    "        x = self.fc4(x)\n",
    "        # print(f'fc3: {x.shape}')\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0833e17-775e-415b-8819-e42784b88065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ../code/team2_model.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Team2Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(2, 128, 8, dtype=torch.float32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Conv1d(128, 256, 8, dtype=torch.float32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Conv1d(256, 512, 8, dtype=torch.float32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Conv1d(512, 1024, 8, dtype=torch.float32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.BatchNorm1d(1024),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.LazyLinear(512, dtype=torch.float32)\n",
    "        self.fc2 = nn.Linear(512, num_classes, dtype=torch.float32)\n",
    "        # self.fc = nn.Sequential(\n",
    "        #     nn.LazyLinear(512, dtype=torch.float32),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(512, num_classes, dtype=torch.float32),\n",
    "        #     nn.ReLU(),\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        x = x.flatten(1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        #return F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33559090-ec6d-43b8-9d54-e6d337bd35cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ../code/team3_model.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# From headley_modrec.py\n",
    "class Team3Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 16, (2, 16))\n",
    "        self.conv2 = nn.Conv2d(16, 8, (1, 8))\n",
    "        self.conv3 = nn.Conv2d(8, 4, (1, 4))\n",
    "        #self.fc1 = nn.Linear(3996, 512)\n",
    "        self.fc1 = nn.LazyLinear(out_features=512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, self.num_classes)\n",
    "\n",
    "        self.activation = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        x = F.tanh(self.conv2(x))\n",
    "        x = F.tanh(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d407168-73c7-42be-80fa-a0dd79600286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ../code/team4_model.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Team4Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.re1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.re2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.re3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.re4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        #self.fc1 = nn.Linear(128 * 256,512)  # I dont exactly know why it is 128x256, but I had to do some debugging and hardcode the required value\n",
    "        self.fc1 = nn.LazyLinear(out_features=512)\n",
    "\n",
    "        self.re5 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.re6 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.re1(self.conv1(x)))\n",
    "        x = self.pool2(self.re2(self.conv2(x)))\n",
    "        x = self.pool3(self.re3(self.conv3(x)))\n",
    "        x = self.pool4(self.re4(self.conv4(x)))\n",
    "        x = self.flat(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.re5(self.fc1(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.re6(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afa62c1-9f53-4548-899e-f6707cd43bb1",
   "metadata": {},
   "source": [
    "## Build a SageMaker Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdfa687-73d1-4958-8f85-67bee063609c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Add training script to source directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98165384-8a6b-46b2-84cd-1384b6fc9b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../code/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../code/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "from team1_model import Team1Model\n",
    "from team2_model import Team2Model\n",
    "from team3_model import Team3Model\n",
    "from team4_model import Team4Model\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "MODELS_OBS_INT = 2048  # 2048 for both spring and summer datasets\n",
    "\n",
    "# For spring dataset: T1 - 2048, T2 - 1024, T3 - 1024, T4 - 512\n",
    "# For summer dataset: T1 - 2048, T2 - 1024, T3 - 512, T4 - 256\n",
    "TEAM1_DATA_OBS_INT = 2048\n",
    "TEAM2_DATA_OBS_INT = 1024\n",
    "TEAM3_DATA_OBS_INT = 1024\n",
    "TEAM4_DATA_OBS_INT = 512\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    num_epochs: int\n",
    "    criterion: Any\n",
    "    optimizer: Any\n",
    "    model_save_dir: str\n",
    "    model_save_filename: str\n",
    "    data_dir: str\n",
    "    data_obs_int: int\n",
    "\n",
    "\n",
    "# set the device on GPU is available otherwise CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"mps\")\n",
    "\n",
    "# Name, [modulation type, num symbols], class label\n",
    "sig_types = [['2-ASK', ['ask', 2], 0],\n",
    "             ['4-ASK', ['ask', 4], 1],\n",
    "             ['8-ASK', ['ask', 8], 2],\n",
    "             ['BPSK', ['psk', 2], 3],\n",
    "             ['QPSK', ['psk', 4], 4],\n",
    "             ['16-QAM', ['qam', 16], 5],\n",
    "             ['Tone', ['constant'], 6],\n",
    "             ['P-FMCW', ['p_fmcw'], 7]]\n",
    "num_classes = len(sig_types)\n",
    "\n",
    "\n",
    "def load_data(channel_path, batch_size, num_batches, num_train_examples, data_obs_int):\n",
    "    training_data = np.zeros((num_train_examples, 1, 2, MODELS_OBS_INT), dtype=np.float32)\n",
    "    training_labels = np.zeros((num_train_examples, num_classes), dtype=np.float32)\n",
    "\n",
    "    last_index = 0\n",
    "    for k in range(num_batches):\n",
    "        # This is used if we have a labeldata folder that stores class labels\n",
    "        label_df = pd.read_csv(f\"{channel_path}/labeldata/example_{k + 1}.csv\")\n",
    "\n",
    "        iq_data = np.fromfile(f\"{channel_path}/iqdata/example_{k + 1}.dat\", np.csingle)\n",
    "        iq_data = np.reshape(iq_data, (-1, data_obs_int))  # Turn the IQ data into chunks of (chunk size) x (data_obs_int)\n",
    "        for j in range(iq_data.shape[0]):\n",
    "            iq_array_norm = iq_data[j][:] / np.max(np.abs(iq_data[j][:]))  # Normalize the observation\n",
    "            iq_array = np.vstack((iq_array_norm.real, iq_array_norm.imag))  # Separate into 2 subarrays - 1 with only real (in-phase), the other only imaginary (quadrature)\n",
    "\n",
    "            # Pad the iq array with zeros to meet the observation length requirement\n",
    "            # This is needed because the CNN models have a fixed input size\n",
    "            iq_array = np.pad(iq_array, ((0, 0), (0, MODELS_OBS_INT - iq_array[0].size)), mode='constant', constant_values=0)\n",
    "\n",
    "            training_data[last_index, 0, :, :] = iq_array\n",
    "            training_labels[last_index, label_df.iloc[j]] = 1.0\n",
    "            last_index += 1\n",
    "\n",
    "    return torch.utils.data.DataLoader([[training_data[i], training_labels[i]] for i in range(num_train_examples)], batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "def train(model, num_epochs, criterion, optim, scheduler, dataloader):\n",
    "    # Put the model in training mode\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for _ in tqdm(range(num_epochs)):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Training step\n",
    "        for idx, (data, labels) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # FOR TESTING ONLY: Break after 10 steps\n",
    "            #if idx == 10:\n",
    "            #    break\n",
    "\n",
    "    return model\n",
    "\n",
    "def setup_training(model, config):\n",
    "    print(f'Loading dataset at {config.data_dir}')\n",
    "    train_dir = config.data_dir #os.path.join(config.data_dir, 'train')\n",
    "    train_iq_files = os.path.join(train_dir, \"iqdata\", \"example_*.dat\")\n",
    "    file_list = glob.glob(train_iq_files)\n",
    "    num_batches = len(file_list)\n",
    "    num_train_examples = num_batches * args.chunk_size\n",
    "    train_data = load_data(train_dir, args.batch_size, num_batches, num_train_examples, config.data_obs_int)\n",
    "\n",
    "    print('Training model')\n",
    "    model = train(model, config.num_epochs, config.criterion, config.optimizer, None, train_data)\n",
    "\n",
    "    save_model_artifacts(model, config.model_save_dir, config.model_save_filename)\n",
    "\n",
    "\n",
    "def save_model_artifacts(model, model_dir: str, model_name: str):\n",
    "    \"\"\"\n",
    "    Saves a PyTorch model to disk\n",
    "    :param model: The PyTorch model to be saved\n",
    "    :param model_dir: The directory to save the model in. Any missing\n",
    "    parent directories will be automatically created.\n",
    "    :param model_name: The name of the model file\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "    filepath = os.path.join(model_dir, model_name)\n",
    "    print(f'Saving model to {filepath}...')\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    print(\" \")\n",
    "    print('Model has been saved')\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"\n",
    "    Parses and loads the command-line arguments sent to the script. These\n",
    "    will be sent by SageMaker when it launches the training container\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print('Parsing command-line arguments...')\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Observation length of the spectrum for each example.\n",
    "    parser.add_argument(\"--obs-int\", type=int, default=2048)\n",
    "    parser.add_argument('--epochs', type=int, default=10)\n",
    "    parser.add_argument('--batch_size', type=int, default=16)\n",
    "    parser.add_argument('--lr', type=float, default=0.001)\n",
    "    parser.add_argument('--s3_checkpoint_path', type=str, default='')\n",
    "    parser.add_argument('--chunk-size', type=int, default=50)\n",
    "\n",
    "    # Data directories\n",
    "    #parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--team_data_dir', type=str, default=os.environ.get('SM_CHANNEL_TEAM_DATA_DIR'))\n",
    "    # parser.add_argument('--team2_data_dir', type=str, default=os.environ.get('SM_CHANNEL_TEAM2_DATA_DIR'))\n",
    "    # parser.add_argument('--team3_data_dir', type=str, default=os.environ.get('SM_CHANNEL_TEAM3_DATA_DIR'))\n",
    "    # parser.add_argument('--team4_data_dir', type=str, default=os.environ.get('SM_CHANNEL_TEAM4_DATA_DIR'))\n",
    "    \n",
    "    parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "\n",
    "    # Checkpoint info\n",
    "    parser.add_argument('--checkpoint_enabled', type=str, default='False')\n",
    "    parser.add_argument('--checkpoint_path', type=str, default='/opt/ml/checkpoints')\n",
    "\n",
    "    print('Completed parsing command-line arguments.')\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Executing the main() function...')\n",
    "    # Parse command-line arguments\n",
    "    args, _ = parse_args()\n",
    "    \n",
    "    if (args.team_data_dir is None): # or (args.team2_data_dir is None) or (args.team3_data_dir is None) or (args.team4_data_dir is None):\n",
    "        raise ValueError(\"A data directory argument wasn't passed in correctly\")\n",
    "\n",
    "    # If running on SageMaker\n",
    "    #model_dir = os.path.join('.', 'model')  # If running locally\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Every model will have the same hyperparameters\n",
    "    # We need to check model performance between these and the hyperparameters chosen by \n",
    "    # the individual teams (commented out below)\n",
    "    learning_rate = args.lr\n",
    "    num_epochs = args.epochs\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam\n",
    "\n",
    "    # Team 1 model\n",
    "    print('Starting team 1 model training')\n",
    "    t1_model = Team1Model(num_classes)\n",
    "    t1_config = TrainingConfig(num_epochs=num_epochs, criterion=criterion,\n",
    "                               optimizer=optimizer(t1_model.parameters(), lr=learning_rate), model_save_dir=args.model_dir,\n",
    "                               model_save_filename='team1_model.pt', data_dir=f'{args.team_data_dir}/1', data_obs_int=TEAM1_DATA_OBS_INT)\n",
    "    setup_training(t1_model, t1_config)\n",
    "    # learning_rate_t1 = 0.001\n",
    "    # num_epochs_t1 = 10\n",
    "    # criterion_t1 = torch.nn.CrossEntropyLoss()\n",
    "    # optimizer_t1 = torch.optim.SGD(modelt1.parameters(), lr=args.lr)\n",
    "    # optimizer_t1 = optimizer(t1_model.parameters(), lr=learning_rate)\n",
    "    # t1_model = train(t1_model, num_epochs, criterion, optimizer_t1, None, train_data)\n",
    "\n",
    "    # Team 2 model\n",
    "    print('Starting team 2 model training')\n",
    "    t2_model = Team2Model(num_classes)\n",
    "    t2_config = TrainingConfig(num_epochs=num_epochs, criterion=criterion,\n",
    "                               optimizer=optimizer(t2_model.parameters(), lr=learning_rate), model_save_dir=args.model_dir,\n",
    "                               model_save_filename='team2_model.pt', data_dir=f'{args.team_data_dir}/2', data_obs_int=TEAM2_DATA_OBS_INT)\n",
    "    setup_training(t2_model, t2_config)\n",
    "    # learning_rate_t2 = 0.01\n",
    "    # num_epochs_t2 = 200\n",
    "    # criterion_t2 = torch.nn.CrossEntropyLoss()\n",
    "    # optimizer_t2 = torch.optim.SGD(modelt2.parameters(), lr=learning_rate)\n",
    "    # optimizer_t2 = optimizer(modelt2.parameters(), lr=learning_rate)\n",
    "    # modelt2 = train(modelt2, num_epochs, criterion, optimizer_t2, None, train_data)\n",
    "    # save_model_artifacts(modelt2, model_dir, 'modelt2.pt')\n",
    "\n",
    "    # Team 3 model\n",
    "    print('Starting team 3 model training')\n",
    "    t3_model = Team3Model(num_classes)\n",
    "    t3_config = TrainingConfig(num_epochs=num_epochs, criterion=criterion,\n",
    "                               optimizer=optimizer(t3_model.parameters(), lr=learning_rate), model_save_dir=args.model_dir,\n",
    "                               model_save_filename='team3_model.pt', data_dir=f'{args.team_data_dir}/3', data_obs_int=TEAM3_DATA_OBS_INT)\n",
    "    setup_training(t3_model, t3_config)\n",
    "    # # learning_rate_t3 = 0.001\n",
    "    # # num_epochs_t3 = 10\n",
    "    # # criterion_t3 = torch.nn.CrossEntropyLoss()\n",
    "    # # optimizer_t3 = torch.optim.SGD(modelt3.parameters(), lr=learning_rate)\n",
    "    # optimizer_t3 = optimizer(modelt3.parameters(), lr=learning_rate)\n",
    "    # modelt3 = train(modelt3, num_epochs, criterion, optimizer_t3, None, train_data)\n",
    "    # save_model_artifacts(modelt3, model_dir, 'modelt3.pt')\n",
    "\n",
    "    # Team 4 model\n",
    "    print('Starting team 4 model training')\n",
    "    t4_model = Team4Model(num_classes)\n",
    "    t4_config = TrainingConfig(num_epochs=num_epochs, criterion=criterion,\n",
    "                               optimizer=optimizer(t4_model.parameters(), lr=learning_rate), model_save_dir=args.model_dir,\n",
    "                               model_save_filename='team4_model.pt', data_dir=f'{args.team_data_dir}/4', data_obs_int=TEAM4_DATA_OBS_INT)\n",
    "    setup_training(t4_model, t4_config)\n",
    "    # # learning_rate_t4 = 0.001\n",
    "    # # num_epochs_t4 = 10\n",
    "    # # criterion_t4 = torch.nn.CrossEntropyLoss()\n",
    "    # # optimizer_t4 = torch.optim.Adam(modelt4.parameters(), learning_rate)\n",
    "    # optimizer_t4 = optimizer(modelt4.parameters(), lr=learning_rate)\n",
    "    # modelt4 = train(modelt4, num_epochs, criterion, optimizer_t4, None, train_data)\n",
    "    # save_model_artifacts(modelt4, model_dir, 'modelt4.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b4c372-5437-4b89-a303-dea2bd806354",
   "metadata": {},
   "source": [
    "## Configure Training Estimator\n",
    "\n",
    "Note: A trailing forward slash is recommended to define a channel corresponding to a folder. For example, the s3://my-bucket/train-01/ channel for the train-01 folder. Without the trailing forward slash, the channel would be ambiguous if there existed another folder s3://my-bucket/train-011/ or file s3://my-bucket/train-01.txt/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310fab32-e75b-402a-a15b-67be3e1cefe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_job_prefix = 'cloudd-rf'\n",
    "output_prefix = f'{base_job_prefix}/training'\n",
    "\n",
    "timestamp = str(time.time()).split('.')[0]\n",
    "code_location = f\"s3://{output_bucket}/{output_prefix}/{timestamp}/code\"\n",
    "\n",
    "instance_count = 1\n",
    "\n",
    "# Be sure to update the chunk-size and obs-int hyperparameters so the IQ data gets parsed correctly\n",
    "hyperparameters = {\n",
    "                    \"lr\": 0.001,\n",
    "                    \"batch_size\": 16,\n",
    "                    \"epochs\": 10,\n",
    "                    \"obs-int\": 2048,\n",
    "                    \"chunk-size\": 5000\n",
    "                }\n",
    "   \n",
    "metric_definitions = [{'Name': 'loss',      'Regex': \"'loss': ([0-9\\\\.]+)\"},\n",
    "                      {'Name': 'recall',       'Regex': \"'recall': ([0-9\\\\.]+)\"},\n",
    "                      {'Name': 'map50',  'Regex': \"'map50': ([0-9\\\\.]+)\"},\n",
    "                      {'Name': 'map',   'Regex': \"'map': ([0-9\\\\.]+)\"}]\n",
    "\n",
    "\n",
    "distributions = {'parameter_server': {'enabled': False}}\n",
    "DISTRIBUTION_MODE = 'FullyReplicated'\n",
    "train_script = 'train.py'\n",
    "instance_type  = 'ml.g5.xlarge'\n",
    "\n",
    "# Set the training script related parameters\n",
    "train_script_dir = '../code'\n",
    "container_log_level = logging.INFO\n",
    "\n",
    "# Location where the trained model will be stored locally in the container before being uploaded to S3\n",
    "model_local_dir = '/opt/ml/model'\n",
    "model_path = f\"s3://{output_bucket}/{output_prefix}\"\n",
    "\n",
    "# The data folders within the S3 bucket for each team. Each folder should contain \"train\", \"test\", and \"validation\" subfolders.\n",
    "team1_data_in = TrainingInput(s3_data=f\"s3://{default_bucket}/cloudd-rf/preprocess/outputs/1728916913/train/1/\", distribution=DISTRIBUTION_MODE, s3_data_type='S3Prefix', input_mode='FastFile')\n",
    "team2_data_in = TrainingInput(s3_data=f\"s3://{default_bucket}/cloudd-rf/preprocess/outputs/1728916913/train/2/\", distribution=DISTRIBUTION_MODE, s3_data_type='S3Prefix', input_mode='FastFile')\n",
    "team3_data_in = TrainingInput(s3_data=f\"s3://{default_bucket}/cloudd-rf/preprocess/outputs/1728916913/train/3/\", distribution=DISTRIBUTION_MODE, s3_data_type='S3Prefix', input_mode='FastFile')\n",
    "team4_data_in = TrainingInput(s3_data=f\"s3://{default_bucket}/cloudd-rf/preprocess/outputs/1728916913/train/4/\", distribution=DISTRIBUTION_MODE, s3_data_type='S3Prefix', input_mode='FastFile')\n",
    "\n",
    "inputs = {'team1_data_dir': team1_data_in,\n",
    "          'team2_data_dir': team2_data_in,\n",
    "          'team3_data_dir': team3_data_in,\n",
    "          'team4_data_dir': team4_data_in\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc003ba-a546-4644-a4c5-4c991151254f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = image_uris.retrieve(framework='pytorch',region='us-east-1',version='1.13.1',py_version='py39',image_scope='training', instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e07a6-ae6f-4ae4-aead-75b3b7fd697a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator = Estimator(  image_uri,\n",
    "                        entry_point=train_script,\n",
    "                        source_dir=train_script_dir,\n",
    "                        output_path=model_path,\n",
    "                        distribution=distributions,\n",
    "                        instance_type=instance_type,\n",
    "                        instance_count=instance_count,\n",
    "                        hyperparameters=hyperparameters,\n",
    "                        # metric_definitions=metric_definitions,\n",
    "                        role=role,\n",
    "                        code_location=code_location,\n",
    "                        base_job_name=f'{base_job_prefix}-training',\n",
    "                        container_log_level=container_log_level,\n",
    "                        enable_sagemaker_metrics=False,\n",
    "                        input_mode=\"FastFile\",\n",
    "                        script_mode=True,\n",
    "                        disable_output_compression=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1ed12-12d2-434f-b928-e187b8d5874f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.fit(inputs=inputs, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0536eff4-d6c0-467c-b565-66dc7fc0370b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75fc2a-a528-4b12-8d83-163fc82c741b",
   "metadata": {},
   "source": [
    "## Get Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863d58a3-438a-4348-bf84-f4a65da640c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = estimator.model_data\n",
    "\n",
    "print(f\"Model artifact files are uploaded here: {model_path} ========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26977e7e-e7fa-4a4d-8f24-664195f317a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp {model_path} models.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0f6269-8f21-458a-abaf-d7f48700c4dc",
   "metadata": {},
   "source": [
    "### Untar the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d861d5d-6d87-4887-af66-9ae4e40b7938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar -xzvf models.tar.gz ../data/summer_models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e037913c-8eaa-420d-bb57-12df16cced32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
