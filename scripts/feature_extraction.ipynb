{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction using PyTorch Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a SageMaker Processing Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ../code/feature_extraction.py\n",
    "import os\n",
    "import argparse\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import math\n",
    "from random import sample\n",
    "\n",
    "from tqdm import tqdm\n",
    "from gymnasium import spaces\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from stable_baselines3 import PPO\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard.writer import SummaryWriter \n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "SIG_TYPES = [['2-ASK', ['ask', 2], 0],\n",
    "             ['4-ASK', ['ask', 4], 1],\n",
    "             ['8-ASK', ['ask', 8], 2],\n",
    "             ['BPSK', ['psk', 2], 3],\n",
    "             ['QPSK', ['psk', 4], 4],\n",
    "             ['16-QAM', ['qam', 16], 5],\n",
    "             ['Tone', ['constant'], 6],\n",
    "             ['P-FMCW', ['p_fmcw'], 7]]\n",
    "NUM_CLASSES = len(SIG_TYPES)\n",
    "sig_names = [i[0] for i in SIG_TYPES]\n",
    "\n",
    "NUM_COMPONENTS = 2\n",
    "NUM_SAMPLES = 700\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    'model': {\n",
    "        'obs_int': 2048,\n",
    "    },\n",
    "    1: {\n",
    "        'plot': True,\n",
    "        'obs_int': 2048,\n",
    "        'fc_layer': 'fc3',\n",
    "        'params_to_plot': ['snr'],\n",
    "        'bandwidths': [0.5],\n",
    "        'center_freqs': [0.5],\n",
    "        'sig_types': 'all',\n",
    "        'snrs': [5, 10, 14]\n",
    "    },\n",
    "    2: {\n",
    "        'plot': True,\n",
    "        'obs_int': 1024,\n",
    "        'fc_layer': 'fc1',\n",
    "        'params_to_plot': ['bandwidth', 'cent_freq', 'obs_int', 'snr'],\n",
    "        'bandwidths': [0.5],\n",
    "        'center_freqs': [0.5],\n",
    "        'sig_types': 'all',\n",
    "        'snrs': [14]\n",
    "    },\n",
    "    3: {\n",
    "        'plot': True,\n",
    "        'obs_int': 512,\n",
    "        'fc_layer': 'fc3',\n",
    "        'params_to_plot': ['bandwidth', 'cent_freq', 'obs_int', 'snr'],\n",
    "        'bandwidths': [0.5],\n",
    "        'center_freqs': [0.5],\n",
    "        'sig_types': [],\n",
    "        'snrs': [14]\n",
    "    },\n",
    "    4: {\n",
    "        'plot': True,\n",
    "        'obs_int': 256,\n",
    "        'fc_layer': 'fc2',\n",
    "        'params_to_plot': ['bandwidth', 'cent_freq', 'obs_int', 'sig_type', 'snr'],\n",
    "        'bandwidths': [0.05, 0.2525, 0.5],\n",
    "        'center_freqs': [256, 1024, 2048],\n",
    "        'sig_types': 'all',\n",
    "        'snrs': [5, 10, 14]\n",
    "    }\n",
    "}\n",
    "\n",
    "COLORS = ['Blue', 'Orange', 'Green', 'Red', 'Purple', 'Brown', px.colors.qualitative.Plotly[6], 'Gray']\n",
    "\n",
    "def float_list(arg):\n",
    "    return list(map(float, arg.split(',')))\n",
    "\n",
    "def int_list(arg):\n",
    "    return list(map(int, arg.split(',')))\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Number of samples per file.\n",
    "    parser.add_argument(\"--num-sensors\", type=int, default=4)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=1)\n",
    "    parser.add_argument(\"--samples-per-batch\", type=int, default=1000) # CHUNK_SIZE\n",
    "    parser.add_argument(\"--input-path\", type=str, default=os.getenv(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--output-path\", type=str, default=os.getenv(\"SM_OUTPUT_DIR\"))\n",
    "    parser.add_argument(\"--model-path\", type=str, default=os.getenv(\"SM_MODEL_DIR\"))\n",
    "    \n",
    "    return parser.parse_known_args()\n",
    "\n",
    "def load_models(num_sensors, batch_size, samples_per_batch, input_path, model_path, device):\n",
    "    global NUM_CLASSES\n",
    "    print (f\"Loading Models\")\n",
    "    import importlib\n",
    "    models_config = {\n",
    "        'team_models': {}\n",
    "    }\n",
    "    for sensor in range(1, num_sensors+1):\n",
    "        models_config['team_models'][sensor] = {\n",
    "           'model': None,\n",
    "           'dataloader': None,\n",
    "           'params': None,\n",
    "           'importance': None,\n",
    "           'features': None\n",
    "        }\n",
    "        # Dynamically import each team model class and instantiate model from it\n",
    "        module_name = f'team{sensor}_model'\n",
    "        class_name = f'Team{sensor}Model'\n",
    "        module = importlib.import_module(module_name)\n",
    "        class_ = getattr(module, class_name)\n",
    "        team_model = class_(NUM_CLASSES)\n",
    "        team_model.load_state_dict(torch.load(f'{model_path}/team{sensor}_model.pt', map_location=torch.device(device)))\n",
    "        team_model.eval()\n",
    "        team_model.to(device)\n",
    "        print (f\"Loaded Team {sensor} model\")\n",
    "        models_config['team_models'][sensor]['model'] = team_model\n",
    "\n",
    "        # Get the number of trainable parameters in each of the teams' models\n",
    "        team_params = sum(p.numel() for p in team_model.parameters() if p.requires_grad)\n",
    "        models_config['team_models'][sensor]['params'] = team_params\n",
    "\n",
    "    return models_config\n",
    "\n",
    "def get_num_samples(iq_input_path, samples_per_batch):\n",
    "    joined_files = os.path.join(iq_input_path, \"iqdata\", \"example_*.dat\") \n",
    "    joined_list = glob.glob(joined_files)\n",
    "    num_batches = len(joined_list)\n",
    "    num_samples = num_batches * samples_per_batch\n",
    "    return num_batches, num_samples\n",
    "  \n",
    "def load_data(channel_path, batch_size, num_batches, num_train_examples, data_obs_int):\n",
    "    training_data = np.zeros((num_train_examples, 1, 2, MODEL_CONFIG['model']['obs_int']), dtype=np.float32)\n",
    "    training_labels = np.zeros((num_train_examples, NUM_CLASSES), dtype=np.float32)\n",
    "    last_index = 0\n",
    "    for k in range(num_batches):\n",
    "        # This is used if we have a labeldata folder that stores class labels\n",
    "        label_df = pd.read_csv(f\"{channel_path}/labeldata/example_{k + 1}.csv\")\n",
    "        num_nans = 0\n",
    "        iq_file_name = f\"{channel_path}/iqdata/example_{k + 1}.dat\"\n",
    "        iq_data = np.fromfile(iq_file_name, np.csingle)\n",
    "        iq_data = np.reshape(iq_data, (-1, data_obs_int))  # Turn the IQ data into chunks of (chunk size) x (data_obs_int)\n",
    "        for j in range(iq_data.shape[0]):\n",
    "            # Check if the current row contains NaN values\n",
    "            if np.isnan(np.sum(iq_data[j][:])):    \n",
    "                num_nans += 1\n",
    "            else:\n",
    "                iq_array_norm = iq_data[j][:] / np.max(np.abs(iq_data[j][:]))  # Normalize the observation\n",
    "                iq_array = np.vstack((iq_array_norm.real, iq_array_norm.imag))  # Separate into 2 subarrays - 1 with only real (in-phase), the other only imaginary (quadrature)\n",
    "\n",
    "                # Pad the iq array with zeros to meet the observation length requirement\n",
    "                # This is needed because the CNN models have a fixed input size\n",
    "                iq_array = np.pad(iq_array, ((0, 0), (0, MODEL_CONFIG['model']['obs_int'] - iq_array[0].size)), mode='constant', constant_values=0)\n",
    "\n",
    "                training_data[last_index, 0, :, :] = iq_array\n",
    "                training_labels[last_index, label_df.iloc[j]] = 1.0\n",
    "            last_index += 1\n",
    "        \n",
    "        if num_nans > 0:\n",
    "            print(f'Found {num_nans} rows containing NaNs in {iq_file_name}')\n",
    "    return torch.utils.data.DataLoader([[training_data[i], training_labels[i]] for i in range(num_train_examples)], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def get_sensor_param_dir(sensor, param, input_path):\n",
    "    validation_dir = os.path.join(input_path, str(sensor), param)\n",
    "    root_data_dir = os.listdir(validation_dir)\n",
    "    return validation_dir, root_data_dir\n",
    "\n",
    "def get_dataloader(sensor, param, param_value, input_path, samples_per_batch, batch_size):\n",
    "    validation_dir = os.path.join(input_path, str(sensor), param, str(param_value))\n",
    "    num_batches, num_samples = get_num_samples(validation_dir, samples_per_batch)\n",
    "    dataloader = load_data(validation_dir, batch_size, num_batches, num_samples, MODEL_CONFIG[sensor]['obs_int'])\n",
    "\n",
    "    return num_batches, dataloader\n",
    "    \n",
    "def load_labels(validation_dir, num_batches):\n",
    "    labels = torch.stack([torch.nn.functional.one_hot(torch.tensor(pd.read_csv(os.path.join(validation_dir, f'labeldata/example_1.csv')).iloc[:,0])) for i in range(num_batches)]).numpy()\n",
    "    labels = labels.reshape((labels.shape[0] * labels.shape[1], labels.shape[2]))\n",
    "    return labels\n",
    "\n",
    "def load_features(team_model, dataloader, layer, device):\n",
    "    features = {}\n",
    "\n",
    "    def get_features(name):\n",
    "        def hook(model, input, output):\n",
    "            features[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    selected_layer = getattr(team_model, layer)  #sometimes its just model or model.module\n",
    "    input_features = selected_layer.in_features\n",
    "    handle = selected_layer.register_forward_hook(get_features('feats'))\n",
    "\n",
    "    feats_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Feed the IQ data into the model\n",
    "    for idx, (inputs, labels) in tqdm(enumerate(dataloader)):\n",
    "        with torch.inference_mode():\n",
    "            preds = team_model(inputs.to(device))\n",
    "        feats_list.append(features['feats'].cpu().numpy())\n",
    "        labels_list.append(labels.numpy())\n",
    "        if idx == NUM_SAMPLES:  # Including too many samples can make the plot difficult to read\n",
    "            break\n",
    "\n",
    "    feats_list = np.concatenate(feats_list)\n",
    "    labels_list = np.concatenate(labels_list)\n",
    "\n",
    "    features = np.array(feats_list)\n",
    "    features = torch.tensor(features)\n",
    "    features = features.reshape(-1, features.shape[-1])\n",
    "    #print(\"features size: \", features.size())\n",
    "    #print (type(features))\n",
    "        \n",
    "    handle.remove()\n",
    "    \n",
    "    return features, labels_list\n",
    "    \n",
    "def plot_feature_extraction_over_param(models_config, param, num_sensors, batch_size, samples_per_batch, input_path, output_path, title):\n",
    "    output_artifacts_dir = os.path.join(output_path, 'fusion_plots', 'feature_extraction')\n",
    "    os.makedirs(output_artifacts_dir, exist_ok=True)\n",
    "    \n",
    "    # Load the root directory for the current param being evaluated (e.g. snr)\n",
    "    param_dir, param_vals = get_sensor_param_dir(1, param, input_path)\n",
    "    \n",
    "    MARKER_MIN_SIZE = 5\n",
    "    MARKER_MAX_SIZE = 15\n",
    "    \n",
    "    if param != 'sig_types':\n",
    "        min_param_val = min([float(x) for x in param_vals])\n",
    "        max_param_val = max([float(x) for x in param_vals])\n",
    "        \n",
    "\n",
    "    # Each row is (comp1, comp2, marker size)\n",
    "    sig_points = [np.empty(shape=[0, NUM_COMPONENTS+1]) for i in SIG_TYPES]\n",
    "\n",
    "    for param_val in param_vals:\n",
    "        \n",
    "        # Get padding value based on current param val\n",
    "        constant_vals = np.interp(param_val, [min_param_val, max_param_val], [MARKER_MIN_SIZE, MARKER_MAX_SIZE]) if param != 'sig_types' else 15\n",
    "        \n",
    "        for sensor in range(1, num_sensors+1):\n",
    "            print(f'Extracting features for Team {sensor} model for {param}: {param_val}')\n",
    "            \n",
    "            # Get Dataloader\n",
    "            print (f\"Loading Dataloader for Model {sensor}\")\n",
    "            num_batches, dataloader = get_dataloader(sensor, param, param_val, input_path, samples_per_batch, batch_size)\n",
    "            models_config['team_models'][sensor]['dataloader'] = dataloader\n",
    "        \n",
    "            # Load Features\n",
    "            print (f\"Loading Features for Model {sensor}\")\n",
    "            features, labels_list = load_features(models_config['team_models'][sensor]['model'], dataloader, MODEL_CONFIG[sensor]['fc_layer'], device)\n",
    "            models_config['team_models'][sensor]['features'] = features\n",
    "                        \n",
    "            # Extract features and get data needed for the scatterplot\n",
    "            pca = PCA(n_components=NUM_COMPONENTS)\n",
    "            X_pca = pca.fit_transform(features)\n",
    "            y = np.argmax(labels_list, axis=1)  # Color markers based on ground truth label\n",
    "            for idx in range(len(SIG_TYPES)):                \n",
    "                sig_points[idx] = np.append(sig_points[idx], np.pad(X_pca[(y == idx)], pad_width=((0, 0), (0, 1)), mode='constant', constant_values=constant_vals), axis=0)\n",
    "            \n",
    "            add_signals_to_plot(sig_points, output_artifacts_dir, param, param_val, sensor, MODEL_CONFIG[sensor]['fc_layer'])\n",
    "\n",
    "def add_signals_to_plot(sig_points, output_artifacts_dir, param, param_val, sensor, layer):\n",
    "    title = f\"PCA of Dataset With {param.upper()} {param_val} for Team {sensor} Model, Layer {layer.upper()}\"\n",
    "    # Add traces for each signal type\n",
    "    data = []\n",
    "    for idx in range(len(SIG_TYPES)):\n",
    "        trace = {\n",
    "            'type': 'scatter' if NUM_COMPONENTS == 2 else 'scatter3d',\n",
    "            'mode': 'markers',\n",
    "            'x': sig_points[idx][:,0],\n",
    "            'y': sig_points[idx][:,1],\n",
    "            'marker_symbol': 'circle',\n",
    "            'marker': dict( color=COLORS[idx],\n",
    "                            size=sig_points[idx][:,NUM_COMPONENTS],\n",
    "                            opacity=0.3),\n",
    "            'name':SIG_TYPES[idx][0],\n",
    "            'showlegend': True\n",
    "        }\n",
    "        if NUM_COMPONENTS == 3:\n",
    "            trace['z'] = sig_points[idx][:,2]\n",
    "\n",
    "        data.append(trace)\n",
    "    \n",
    "    fig = go.Figure(data)\n",
    "    \n",
    "    width=800 \n",
    "    height=600\n",
    "    \n",
    "    layout = {\n",
    "        'title': dict(text=title),\n",
    "        'xaxis_title':'Principal Component 1',\n",
    "        'yaxis_title':'Principal Component 2',\n",
    "        'autosize': False,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    }\n",
    "    if NUM_COMPONENTS == 3:\n",
    "        layout['zaxis_title'] = 'Principal Component 3'\n",
    "        width=1200 \n",
    "        height=900\n",
    "        layout['width'] = width\n",
    "        layout['height'] = height\n",
    "\n",
    "    fig.update_layout(layout)\n",
    "    \n",
    "    fig.write_image(file=f'{output_artifacts_dir}/pca_{param.upper()}_{param_val}_team_{sensor}_{layer.upper()}.png', format='png', width=width, height=height)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    args, _ = parse_args()\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print('Using device', device)\n",
    "    \n",
    "    # Load Models\n",
    "    models_config = load_models(args.num_sensors, args.batch_size, args.samples_per_batch, args.input_path, args.model_path, device)\n",
    "    \n",
    "    x_axis_labels = {\n",
    "        'snr': 'Signal-to-Noise Ratio (dB)',\n",
    "        'cent_freqs': 'Center Frequency',\n",
    "        'sig_types': 'Signal Type'\n",
    "    }\n",
    "    \n",
    "    for param in ['snr','cent_freqs', 'sig_types']:\n",
    "        plot_feature_extraction_over_param(models_config, param, args.num_sensors, args.batch_size, args.samples_per_batch, args.input_path, args.output_path, x_axis_labels[param])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Testing of File\n",
    "Use the cell below to perform local testing of the file before launching a larger job on SageMaker. Make sure to update the file paths and args depending on the sample data in your local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install gymnasium xgboost stable-baselines3 stable-baselines3[extra] tqdm rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python ../code/feature_extraction.py --num-sensors 4 --batch-size 1 --samples-per-batch 100 --input-path \"/root/ClouddRF_Final/cloudd-rf/data/test\" --output-path \"/root/ClouddRF_Final/cloudd-rf/output\" --model-path \"/root/ClouddRF_Final/cloudd-rf/models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "Setting up the environment, load the libraries, and define the parameter for the entire notebook.\n",
    "\n",
    "Run the cell below to ensure latest version of SageMaker is installed in your kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "account = sagemaker_session.account_id()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "base_job_prefix = \"cloudd-rf\"\n",
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    ")\n",
    "import time \n",
    "\n",
    "timestamp = str(time.time()).split('.')[0]\n",
    "output_prefix = f'{base_job_prefix}/evaluation/outputs/{timestamp}'\n",
    "output_s3_uri = f's3://{default_bucket}/{output_prefix}'\n",
    "code_location = f's3://{default_bucket}/{base_job_prefix}/evaluation/code'\n",
    "\n",
    "# S3 Location of Validation Dataset\n",
    "# UPDATE the var below with the s3 prefix (just the portion after /preprocess) of where the validation data is located\n",
    "s3_validation_data = f's3://{default_bucket}/{base_job_prefix}/preprocess/outputs/1730252950/test/'\n",
    "\n",
    "# UPDATE the var below with the s3 prefix (just the portion after /training) of where the team models are located\n",
    "team_model_prefix = 'training/pipelines-pvbseqe6oz4t-TrainModel-lVGjYR0zh2/output/model/'\n",
    "s3_team_model_path = f's3://{default_bucket}/{base_job_prefix}/{team_model_prefix}'\n",
    "\n",
    "processing_instance_type = \"ml.g5.xlarge\"\n",
    "processing_instance_count = 1\n",
    "env_vars = {\n",
    "    \"SM_CHANNEL_TEST\": \"/opt/ml/processing/input/data/test\",\n",
    "    \"SM_MODEL_DIR\": \"/opt/ml/processing/model\",\n",
    "    \"SM_OUTPUT_DIR\": \"/opt/ml/processing/output\"\n",
    "}\n",
    "\n",
    "pytorch_processor = PyTorchProcessor(\n",
    "    framework_version='1.13.1',\n",
    "    py_version=\"py39\",\n",
    "    role=role,\n",
    "    env=env_vars,\n",
    "    instance_count=processing_instance_count,\n",
    "    instance_type=processing_instance_type,\n",
    "    base_job_name = f\"{base_job_prefix}-feature-extraction\",\n",
    "    code_location=code_location\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Processing Script Arguments\n",
    "chunk_size = 100\n",
    "batch_size = 1\n",
    "num_sensors = 4 # Number of teams with distinct models\n",
    "\n",
    "arguments = [\n",
    "    \"--samples-per-batch\", str(chunk_size), \n",
    "    \"--batch-size\", str(batch_size),\n",
    "    \"--num-sensors\", str(num_sensors)\n",
    "]\n",
    "\n",
    "code = 'feature_extraction.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pytorch_processor.run(\n",
    "                        code=code,\n",
    "                        source_dir='../code',\n",
    "                        arguments=arguments,\n",
    "                        inputs=[\n",
    "                            ProcessingInput(source=s3_test_data, destination=env_vars[\"SM_CHANNEL_TEST\"], s3_data_type='S3Prefix'),\n",
    "                            ProcessingInput(source=s3_team_model_path, destination=env_vars[\"SM_MODEL_DIR\"], s3_data_type='S3Prefix')\n",
    "                       ],\n",
    "                        outputs=[\n",
    "                            ProcessingOutput(source=env_vars[\"SM_OUTPUT_DIR\"], destination = output_s3_uri)\n",
    "                        ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "response = s3_client.list_objects_v2(Bucket=default_bucket, Prefix=output_s3_uri)\n",
    "files = response.get(\"Contents\")\n",
    "\n",
    "for file in files:\n",
    "    print(f\"file_name: {file['Key']}, size: {file['Size']}\")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.13-gpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
