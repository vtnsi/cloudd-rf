{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing using PyTorch Processor\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Prerequisites](#Prerequisites)\n",
    "3. [Setup](#Setup)\n",
    "4. [Build a SageMaker Processing Job](#Build-a-SageMaker-Processing-Job)\n",
    "    1. [Review Processcikit-learn Script](#Processing-Data-Generation-Scripts)\n",
    "    2. [Configure Processing Job](#Configure-Processing-Job)\n",
    "5. [Review Outputs](#Review-Outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Preprocess dataset before model training is an important step in the overall MLOps process. In this lab you will learn how to use [PyTorchProcessor](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job-frameworks-pytorch.html), a type of SageMaker processor that uses PyTorch scripts in a container image provided and maintained by SageMaker to preprocess data or evaluate models.\n",
    "\n",
    "The example script will generate metadata and IQ data for the train, validation, and test channels, and finally export the data files to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Download the notebook into your environment, and you can run it by simply execute each cell in order. To understand what's happening, you'll need:\n",
    "\n",
    "- Access to the SageMaker default S3 bucket. All the files related to this lab will be stored under the \"rare-planes\" prefix of the bucket.\n",
    "- Familiarity with Python and numpy\n",
    "- Basic familiarity with AWS S3.\n",
    "- Basic understanding of AWS Sagemaker.\n",
    "- Basic familiarity with AWS Command Line Interface (CLI) -- ideally, you should have it set up with credentials to access the AWS account you're running this notebook from.\n",
    "- SageMaker Studio is preferred for the full UI integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Setting up the environment, load the libraries, and define the parameter for the entire notebook.\n",
    "\n",
    "Run the cell below to ensure latest version of SageMaker is installed in your kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "account = sagemaker_session.account_id()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "base_job_prefix = \"cloudd-rf\"\n",
    "s3_raw_data = f's3://{default_bucket}/{base_job_prefix}/data'\n",
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a SageMaker Processing Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Data Generation Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ../code/preprocessing.py\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "# Datagen Imports\n",
    "from cloudd_rf.datagen.iqdata_gen import iqdata_gen\n",
    "from cloudd_rf.datagen.burst_def import burst_def\n",
    "\n",
    "output_path = '/opt/ml/processing/output'\n",
    "#output_path = '/root/ClouddRF_Final/cloudd-rf/data2'\n",
    "\n",
    "# Spectrum Parameters\n",
    "sig_types = [['2-ASK',  ['ask', 2], 0],\n",
    "             ['4-ASK',  ['ask', 4], 1],\n",
    "             ['8-ASK',  ['ask', 8], 2],\n",
    "             ['BPSK',   ['psk', 2], 3], \n",
    "             ['QPSK',   ['psk', 4], 4],\n",
    "             ['16-QAM', ['qam', 16], 5],\n",
    "             ['Tone', ['constant'], 6],\n",
    "             ['P-FMCW', ['p_fmcw'], 7]]\n",
    "\n",
    "# Starting sample min and max of any created signal with possible range [0, obs_int].\n",
    "start_bounds = [0, 0]\n",
    "obs_ints = [2048, \n",
    "            1024, \n",
    "            512, \n",
    "            256]\n",
    "bandwidth_bounds = [(0.1, 0.5),\n",
    "                    (0.25, 0.5),\n",
    "                    (0.25, 0.5),\n",
    "                    (0.25, 0.5)]\n",
    "cent_freq_bounds = [(-0.01, 0.01),\n",
    "                    (-0.01, 0.01),\n",
    "                    (-0.05, 0.05),\n",
    "                    (-0.01, 0.01)]\n",
    "snr_bounds = [(5, 15),\n",
    "              (0, 20),\n",
    "              (5, 20),\n",
    "              (5, 20)]\n",
    "\n",
    "def float_list(arg):\n",
    "    return list(map(float, arg.split(',')))\n",
    "\n",
    "def int_list(arg):\n",
    "    return list(map(int, arg.split(',')))\n",
    "\n",
    "def bool_arg(arg):\n",
    "    return arg == 'True'\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Number of samples per file.\n",
    "    parser.add_argument(\"--chunk-size\", type=int, default=10)\n",
    "    # Number of different radio frequency spectrum examples to be created for the dataset.\n",
    "    parser.add_argument(\"--sample-size\", type=int, default=1000)\n",
    "    # Percentage of samples that will be used for the training dataset\n",
    "    parser.add_argument(\"--train-split\", type=float, default=0.7)\n",
    "    # Percentage of samples that will be used for the validation dataset\n",
    "    parser.add_argument(\"--val-split\", type=float, default=0.1)\n",
    "    # Percentage of samples that will be used for the test dataset\n",
    "    parser.add_argument(\"--test-split\", type=float, default=0.2)\n",
    "    # The maximum number of signals that will be created in the spectrum (note: if allow_collision=False, the generator will attempt to fit this many signals without overlap in the spectrum until max_trials is reached).\n",
    "    parser.add_argument(\"--max-sigs\", type=int, default=1)\n",
    "    # How many tries the generator will attempt to fit the maximum number of signals in the spectrum (note: if allow_collision=True, this parameter doesn't do anything).\n",
    "    parser.add_argument(\"--max-trials\", type=int, default=100000)\n",
    "    # Bandwidth min and max of any created signal with possible range (0.0, 1.0).\n",
    "    # True: Signals can be overlapped in time and/or frequency. False: No overlap in signals but may not generate max_sigs.\n",
    "    parser.add_argument(\"--allow-collisions\", type=bool_arg, default=False)\n",
    "    # Image Parameters\n",
    "    # Image width (in pixels).\n",
    "    parser.add_argument(\"--image-width\", type=int, default=1000)\n",
    "    # Image height (in pixels).\n",
    "    parser.add_argument(\"--image-height\", type=int, default=500)\n",
    "    # FFT size used to generate the spectrogram image.\n",
    "    parser.add_argument(\"--fft-size\", type=int, default=256)\n",
    "    # FFT overlap used to generate the spectrogram image.\n",
    "    parser.add_argument(\"--overlap\", type=int, default=255)\n",
    "    # Seed for the random number generator for repeatability (note: script must use all of the same generation parameter bounds and values).\n",
    "    parser.add_argument(\"--rand-seed\", type=int, default=1337)\n",
    "    # Number of discrete sensors to generate data for\n",
    "    parser.add_argument(\"--num-sensors\", type=int, default=4)\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "def create_path(path):\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "def gen_data(num_samples, bandwidth_bounds, cent_freq_bounds, snr_bounds, sig_types, rng, iq_gen, channel, num_sensors):\n",
    "    dataset = [[None for x in range(num_samples)] for x in range(num_sensors)]\n",
    "    labels = []\n",
    "    \n",
    "    for k in range(num_samples):\n",
    "        if channel == \"test\":\n",
    "            sig_type_num = sig_types[2]\n",
    "        else:\n",
    "            sig_type_num = rng.choice(len(sig_types))\n",
    "\n",
    "        burst_list = []\n",
    "        for kk in range(num_sensors):\n",
    "            burst_list.append(burst_def(rng.uniform(bandwidth_bounds[kk][0], bandwidth_bounds[kk][1]), rng.uniform(cent_freq_bounds[kk][0], cent_freq_bounds[kk][1]), obs_ints[kk], rng.uniform(snr_bounds[kk][0], snr_bounds[kk][1])))\n",
    "\n",
    "        if channel == \"test\":\n",
    "            data, burst_list = iq_gen.gen_iq(sig_types, burst_list)\n",
    "        else:\n",
    "            data, burst_list = iq_gen.gen_iq(sig_types[sig_type_num], burst_list)\n",
    "        \n",
    "        for kk in range(num_sensors):\n",
    "            dataset[kk][k] = data[kk]\n",
    "\n",
    "        labels.append(sig_type_num)\n",
    "    \n",
    "    return dataset, labels\n",
    "\n",
    "def chunk_data(chunk_size, num_samples, iq_output_path, label_output_path, dataset, labels):\n",
    "    CHUNK_SIZE = chunk_size\n",
    "    iq_array = None\n",
    "    label_array = None\n",
    "    CHUNK = 0\n",
    "    start_time = time.time()\n",
    "    for k in range(num_samples):\n",
    "        # Create Radio Frequency Signal Example\n",
    "        # Usage Notes: \n",
    "        #   - Generated signal is a vector of complex radio frequency samples (i.e. each sample is of the form A+jB).\n",
    "        #   - For neural network training and testing, you will need to convert this complex data to a real format.\n",
    "        #       - Option 1: Real and Imaginary components of each sample are stored as seperate 'channels'.\n",
    "        #       - Option 2: Real and Imaginary components of each sample are stored as seperate 'rows'.\n",
    "        label = [labels[k]]\n",
    "        iq_data = dataset[k]\n",
    "        iq_data = [iq_data.astype(np.csingle)]\n",
    "\n",
    "        if (label_array is not None):\n",
    "            label_array = label_array + label\n",
    "        else:\n",
    "            label_array = label\n",
    "            \n",
    "        if (iq_array is not None):\n",
    "            iq_array = np.concatenate((iq_array,iq_data),axis=0)\n",
    "        else:\n",
    "            iq_array = np.array(iq_data)\n",
    "\n",
    "        if k > 0 and (k+1) % CHUNK_SIZE == 0:   \n",
    "            CHUNK += 1\n",
    "            write_chunk(iq_array, label_array, CHUNK, iq_output_path, label_output_path)\n",
    "            iq_array = None\n",
    "            label_array = None\n",
    "            print('Finished chunk ' + str(CHUNK) + ' of ' + str(int(num_samples/CHUNK_SIZE)) + ' generated. Time taken: ' + str(time.time()-start_time))\n",
    "            start_time = time.time()\n",
    "            \n",
    "\n",
    "def write_chunk(iq_data, labels, chunk, iq_output_path, label_output_path):\n",
    "    # Save Radio Frequency Data to File \n",
    "    # Usage Notes: \n",
    "    #   - This is the data that acts as the input for neural network training. \n",
    "    #   - File is in the numpy csingle format (https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.csingle) and will need to be loaded from file as such.\n",
    "    iqdata_file_name = f'{iq_output_path}/example_{str(chunk)}.dat'\n",
    "    iq_data.tofile(iqdata_file_name)\n",
    "    \n",
    "    # Save Radio Frequency Spectrogram Image to File\n",
    "    # Usage Notes: \n",
    "    #   - This is for optional visualization purposes only and not to be used as the input for neural network training. \n",
    "    #   - Can be safely commented out to speed up data generation times.\n",
    "    # imdata_file_name = f'{im_output_path}/example_{str(chunk)}.png'\n",
    "    # im_gen.gen_image(imdata_file_name, burst_metadata, iq_data, False)\n",
    "    # pyplot.close()\n",
    "\n",
    "    # Save Radio Frequency Metadata to File\n",
    "    # Usage Notes: \n",
    "    #   - This is all of the metadata that will be useful for neural network training and testing.\n",
    "    #   - For training, only the 'Signal Type' field is needed.\n",
    "    #   - For testing, all fields will be useful for quantifying performance as a function of the signal parameters (e.g. performance as a function of 'SNR', 'Duration', 'Signal Type', etc.).\n",
    "    label_file_name = f'{label_output_path}/example_{str(chunk)}.csv'\n",
    "    fid = open(label_file_name, 'w', encoding='UTF8')\n",
    "    writer = csv.writer(fid)\n",
    "\n",
    "    header = ['Label']\n",
    "    writer.writerow(header)\n",
    "    for label in labels:\n",
    "        data = [label]\n",
    "        writer.writerow(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    args, _ = parse_args()\n",
    "    \n",
    "    # Initalize Generators\n",
    "    rng = np.random.default_rng(args.rand_seed)\n",
    "\n",
    "    iq_gen = iqdata_gen(obs_int=np.max(obs_ints), num_sensors=args.num_sensors)\n",
    "    \n",
    "    channel_sizes = {\n",
    "        'train': int(args.sample_size * args.train_split),\n",
    "        'validation': int(args.sample_size * args.val_split),\n",
    "        'test': int(args.sample_size * args.test_split)\n",
    "    }\n",
    "    \n",
    "    for channel in ['train','validation','test']:\n",
    "\n",
    "        print(f'Generating data for {channel} channel')\n",
    "        \n",
    "        num_samples = channel_sizes[channel]\n",
    "\n",
    "        # Create Dataset\n",
    "        if channel == 'test':\n",
    "            # Generate Test Data for Each Sig Type\n",
    "            print(f'Generating data for SIGNAL TYPES')\n",
    "            for sig_type in sig_types:\n",
    "                print(f'Generating data for {sig_type[0]}')\n",
    "                dataset, labels = gen_data(num_samples, bandwidth_bounds, cent_freq_bounds, snr_bounds, sig_type, rng, iq_gen, channel, args.num_sensors)\n",
    "                for i in range(1, args.num_sensors+1):\n",
    "                    print(f'Generating data for sensor {i}')\n",
    "                    iq_output_path = f\"{output_path}/{channel}/{i}/sig_types/{sig_type[0]}/iqdata\"\n",
    "                    label_output_path = f\"{output_path}/{channel}/{i}/sig_types/{sig_type[0]}/labeldata\"\n",
    "                    create_path(iq_output_path)\n",
    "                    create_path(label_output_path)\n",
    "                    chunk_data(args.chunk_size, num_samples, iq_output_path, label_output_path, dataset[i-1], labels)\n",
    "                \n",
    "\n",
    "            # Generate Test Data for Each SNR\n",
    "            print(f'Generating data for SNRs')\n",
    "            snrs = range(0,15)\n",
    "            for snr in snrs:\n",
    "                print(f'Generating data for {snr}')\n",
    "                snr_bounds = [(snr, snr),\n",
    "                (snr, snr),\n",
    "                (snr, snr),\n",
    "                (snr, snr)]\n",
    "                dataset, labels = gen_data(num_samples, bandwidth_bounds, cent_freq_bounds, snr_bounds, sig_types, rng, iq_gen, \"snr\", args.num_sensors)\n",
    "                for i in range(1, args.num_sensors+1):\n",
    "                    print(f'Generating data for sensor {i}')\n",
    "                    iq_output_path = f\"{output_path}/{channel}/{i}/snr/{snr}/iqdata\"\n",
    "                    label_output_path = f\"{output_path}/{channel}/{i}/snr/{snr}/labeldata\"\n",
    "                    create_path(iq_output_path)\n",
    "                    create_path(label_output_path)\n",
    "                    chunk_data(args.chunk_size, num_samples, iq_output_path, label_output_path, dataset[i-1], labels)\n",
    "                \n",
    "\n",
    "            # Generate Test Data for Each Center Frequency\n",
    "            cent_freqs = np.linspace(0.1,0.5,21)\n",
    "            print(f'Generating data for CENTER FREQUENCIES')\n",
    "            for cent_freq in cent_freqs:\n",
    "                print(f'Generating data for {cent_freq}')\n",
    "                cent_freq_bounds = [(cent_freq, cent_freq),\n",
    "                        (cent_freq, cent_freq),\n",
    "                        (cent_freq, cent_freq),\n",
    "                        (cent_freq, cent_freq)]\n",
    "                dataset, labels = gen_data(num_samples, bandwidth_bounds, cent_freq_bounds, snr_bounds, sig_types, rng, iq_gen, \"cent_freqs\", args.num_sensors)\n",
    "                for i in range(1, args.num_sensors+1):\n",
    "                    print(f'Generating data for sensor {i}')\n",
    "                    iq_output_path = f\"{output_path}/{channel}/{i}/cent_freqs/{cent_freq}/iqdata\"\n",
    "                    label_output_path = f\"{output_path}/{channel}/{i}/cent_freqs/{cent_freq}/labeldata\"\n",
    "                    create_path(iq_output_path)\n",
    "                    create_path(label_output_path)\n",
    "                    chunk_data(args.chunk_size, num_samples, iq_output_path, label_output_path, dataset[i-1], labels)\n",
    "        else:\n",
    "            dataset, labels = gen_data(num_samples, bandwidth_bounds, cent_freq_bounds, snr_bounds, sig_types, rng, iq_gen, channel, args.num_sensors)\n",
    "            for i in range(1, args.num_sensors+1):\n",
    "                print(f'Generating {num_samples} samples of data for sensor {i}')\n",
    "                iq_output_path = f\"{output_path}/{channel}/{i}/iqdata\"\n",
    "                label_output_path = f\"{output_path}/{channel}/{i}/labeldata\"\n",
    "                create_path(iq_output_path)\n",
    "                create_path(label_output_path)\n",
    "                chunk_data(args.chunk_size, num_samples, iq_output_path, label_output_path, dataset[i-1], labels)\n",
    "\n",
    "    print(\"Finished running processing job\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Testing Prior to Launching SageMaker Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python ../code/preprocessing.py --chunk-size 10 --sample-size 1000 --max-trials 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    ")\n",
    "import time \n",
    "\n",
    "timestamp = str(time.time()).split('.')[0]\n",
    "output_prefix = f'{base_job_prefix}/preprocess/outputs/{timestamp}'\n",
    "output_s3_uri = f's3://{default_bucket}/{output_prefix}'\n",
    "code_location = f's3://{default_bucket}/{base_job_prefix}/preprocess/code'\n",
    "\n",
    "processing_instance_type = \"ml.c5.18xlarge\"\n",
    "processing_instance_count = 1\n",
    "\n",
    "pytorch_processor = PyTorchProcessor(\n",
    "    framework_version='1.13.1',\n",
    "    py_version=\"py39\",\n",
    "    role=role,\n",
    "    instance_count=processing_instance_count,\n",
    "    instance_type=processing_instance_type,\n",
    "    base_job_name = f\"{base_job_prefix}-preprocess\",\n",
    "    code_location=code_location\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Processing Script Arguments\n",
    "sample_size = 1000\n",
    "train_split = 0.7\n",
    "val_split = 0.1\n",
    "test_split = 0.2\n",
    "max_trials = 1000\n",
    "max_sigs = 1\n",
    "allow_collisions = \"False\"\n",
    "image_width = 1000\n",
    "image_height = 500\n",
    "fft_size = 256\n",
    "overlap = 255\n",
    "rand_seed = 1337\n",
    "chunk_size = 10\n",
    "num_sensors = 4\n",
    "\n",
    "arguments = [\n",
    "    \"--chunk-size\", str(chunk_size), \n",
    "    \"--train-split\", str(train_split), \n",
    "    \"--val-split\", str(val_split), \n",
    "    \"--test-split\", str(test_split),\n",
    "    \"--sample-size\", str(sample_size),\n",
    "    \"--max-sigs\", str(max_sigs),\n",
    "    \"--max-trials\", str(max_trials),\n",
    "    \"--allow-collisions\", allow_collisions,\n",
    "    \"--image-width\", str(image_width),\n",
    "    \"--image-height\", str(image_height),\n",
    "    \"--fft-size\", str(fft_size),\n",
    "    \"--overlap\", str(overlap),\n",
    "    \"--rand-seed\", str(rand_seed)\n",
    "]\n",
    "\n",
    "code = 'preprocessing.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pytorch_processor.run(\n",
    "                        code=code,\n",
    "                        source_dir='../code',\n",
    "                        arguments=arguments,\n",
    "                        outputs=[\n",
    "                            ProcessingOutput(source=\"/opt/ml/processing/output/train\", destination = output_s3_uri +'/train'),\n",
    "                            ProcessingOutput(source=\"/opt/ml/processing/output/test\", destination = output_s3_uri +'/test'),\n",
    "                            ProcessingOutput(source=\"/opt/ml/processing/output/validation\", destination = output_s3_uri +'/validation')\n",
    "                        ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "response = s3_client.list_objects_v2(Bucket=default_bucket, Prefix=output_prefix)\n",
    "files = response.get(\"Contents\")\n",
    "\n",
    "for file in files:\n",
    "    print(f\"file_name: {file['Key']}, size: {file['Size']}\")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
