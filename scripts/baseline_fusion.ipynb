{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Fusion using PyTorch Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Setting up the environment, load the libraries, and define the parameter for the entire notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "account = sagemaker_session.account_id()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "base_job_prefix = \"cloudd-rf\"\n",
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a SageMaker Processing Job\n",
    "There are 3 types of processing jobs depending on which framework you want to use: [AWS Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Fusion Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ../code/baseline_fusion.py\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "SIG_TYPES = [['2-ASK', ['ask', 2], 0],\n",
    "             ['4-ASK', ['ask', 4], 1],\n",
    "             ['8-ASK', ['ask', 8], 2],\n",
    "             ['BPSK', ['psk', 2], 3],\n",
    "             ['QPSK', ['psk', 4], 4],\n",
    "             ['16-QAM', ['qam', 16], 5],\n",
    "             ['Tone', ['constant'], 6],\n",
    "             ['P-FMCW', ['p_fmcw'], 7]]\n",
    "NUM_CLASSES = len(SIG_TYPES)\n",
    "sig_names = [i[0] for i in SIG_TYPES]\n",
    "\n",
    "OBS_INT = {\n",
    "    'model': 2048,\n",
    "    1: 2048,\n",
    "    2: 1024,\n",
    "    3: 512,\n",
    "    4: 256    \n",
    "}\n",
    "\n",
    "FC_LAYERS = {\n",
    "    1: 'fc3',\n",
    "    2: 'fc1',\n",
    "    3: 'fc3',\n",
    "    4: 'fc2'\n",
    "}\n",
    "\n",
    "def float_list(arg):\n",
    "    return list(map(float, arg.split(',')))\n",
    "\n",
    "def int_list(arg):\n",
    "    return list(map(int, arg.split(',')))\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Number of samples per file.\n",
    "    parser.add_argument(\"--num-sensors\", type=int, default=4)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=1)\n",
    "    parser.add_argument(\"--samples-per-batch\", type=int, default=1000) # CHUNK_SIZE\n",
    "    parser.add_argument(\"--input-path\", type=str, default=os.getenv(\"SM_CHANNEL_VAL\"))\n",
    "    parser.add_argument(\"--output-path\", type=str, default=os.getenv(\"SM_OUTPUT_DIR\"))\n",
    "    parser.add_argument(\"--model-path\", type=str, default=os.getenv(\"SM_MODEL_DIR\"))\n",
    "    \n",
    "    return parser.parse_known_args()\n",
    "\n",
    "def load_models(num_sensors, batch_size, samples_per_batch, input_path, model_path, device):\n",
    "    global NUM_CLASSES\n",
    "    print (f\"Loading Models\")\n",
    "    import importlib\n",
    "    models_config = {\n",
    "        'team_models': {},\n",
    "        'reg_fused': {},\n",
    "        'rl_fused': {},\n",
    "        'rfe_fused': {}\n",
    "    }\n",
    "    for sensor in range(1, num_sensors+1):\n",
    "        models_config['team_models'][sensor] = {\n",
    "           'model': None,\n",
    "           'dataloader': None,\n",
    "           'params': None,\n",
    "           'features': None\n",
    "        }\n",
    "        # Dynamically import each team model class and instantiate model from it\n",
    "        module_name = f'team{sensor}_model'\n",
    "        class_name = f'Team{sensor}Model'\n",
    "        module = importlib.import_module(module_name)\n",
    "        class_ = getattr(module, class_name)\n",
    "        team_model = class_(NUM_CLASSES)\n",
    "        team_model.load_state_dict(torch.load(f'{model_path}/team{sensor}_model.pt', map_location=torch.device(device)))\n",
    "        team_model.eval()\n",
    "        team_model.to(device)\n",
    "        print (f\"Loaded Team {sensor} model\")\n",
    "        models_config['team_models'][sensor]['model'] = team_model\n",
    "\n",
    "        # Get the number of trainable parameters in each of the teams' models\n",
    "        team_params = sum(p.numel() for p in team_model.parameters() if p.requires_grad)\n",
    "        print(f'# trainable params, Team {sensor}:', team_model)\n",
    "        models_config['team_models'][sensor]['params'] = team_params\n",
    "    \n",
    "        # Get Dataloaders\n",
    "        print (f\"Loading Dataloader for Model {sensor}\")\n",
    "        num_batches, dataloader = get_dataloaders(sensor, input_path, samples_per_batch, batch_size)\n",
    "        models_config['team_models'][sensor]['dataloader'] = dataloader\n",
    "    \n",
    "        # Load Features\n",
    "        print (f\"Loading Features for Model {sensor}\")\n",
    "        models_config['team_models'][sensor]['features'] = load_features(team_model, dataloader, FC_LAYERS[sensor], sensor, device)\n",
    "    \n",
    "    # Load Labels\n",
    "    print (\"Loading Labels\")\n",
    "    labels = load_labels(input_path, num_batches).numpy()\n",
    "    labels = labels.reshape((labels.shape[0] * labels.shape[1], labels.shape[2]))\n",
    "    labels = np.argmax(labels, axis=1)\n",
    "    models_config['labels'] = labels\n",
    "    models_config['num_batches'] = num_batches\n",
    "\n",
    "    return models_config\n",
    "\n",
    "def get_num_samples(iq_input_path, samples_per_batch):\n",
    "    joined_files = os.path.join(iq_input_path, \"iqdata\", \"example_*.dat\") \n",
    "    joined_list = glob.glob(joined_files)\n",
    "    num_batches = len(joined_list)\n",
    "    num_samples = num_batches * samples_per_batch\n",
    "    return num_batches, num_samples\n",
    "  \n",
    "def load_data(channel_path, batch_size, num_batches, num_train_examples, data_obs_int):\n",
    "    training_data = np.zeros((num_train_examples, 1, 2, OBS_INT['model']), dtype=np.float32)\n",
    "\n",
    "    last_index = 0\n",
    "    for k in range(num_batches):\n",
    "        # This is used if we have a labeldata folder that stores class labels\n",
    "        label_df = pd.read_csv(f\"{channel_path}/labeldata/example_{k + 1}.csv\")\n",
    "        num_nans = 0\n",
    "        iq_file_name = f\"{channel_path}/iqdata/example_{k + 1}.dat\"\n",
    "        iq_data = np.fromfile(iq_file_name, np.csingle)\n",
    "        iq_data = np.reshape(iq_data, (-1, data_obs_int))  # Turn the IQ data into chunks of (chunk size) x (data_obs_int)\n",
    "        for j in range(iq_data.shape[0]):\n",
    "            # Check if the current row contains NaN values\n",
    "            if np.isnan(np.sum(iq_data[j][:])):    \n",
    "                num_nans += 1\n",
    "            else:\n",
    "                iq_array_norm = iq_data[j][:] / np.max(np.abs(iq_data[j][:]))  # Normalize the observation\n",
    "                iq_array = np.vstack((iq_array_norm.real, iq_array_norm.imag))  # Separate into 2 subarrays - 1 with only real (in-phase), the other only imaginary (quadrature)\n",
    "\n",
    "                # Pad the iq array with zeros to meet the observation length requirement\n",
    "                # This is needed because the CNN models have a fixed input size\n",
    "                iq_array = np.pad(iq_array, ((0, 0), (0, OBS_INT['model'] - iq_array[0].size)), mode='constant', constant_values=0)\n",
    "\n",
    "                training_data[last_index, 0, :, :] = iq_array\n",
    "            last_index += 1\n",
    "        \n",
    "        if num_nans > 0:\n",
    "            print(f'Found {num_nans} rows containing NaNs in {iq_file_name}')\n",
    "    return torch.utils.data.DataLoader([training_data[i] for i in range(num_train_examples)], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def get_dataloaders(sensor, input_path, samples_per_batch, batch_size):\n",
    "    validation_dir = os.path.join(input_path, str(sensor))\n",
    "    num_batches, num_samples = get_num_samples(validation_dir, samples_per_batch)\n",
    "    dataloader = load_data(validation_dir, batch_size, num_batches, num_samples, OBS_INT[sensor])\n",
    "\n",
    "    return num_batches, dataloader\n",
    "    \n",
    "def load_labels(input_path, num_batches):\n",
    "    validation_dir = os.path.join(input_path, '1')\n",
    "    labels = torch.stack([torch.nn.functional.one_hot(torch.tensor(pd.read_csv(os.path.join(validation_dir, f'labeldata/example_1.csv')).iloc[:,0])) for i in range(num_batches)])\n",
    "    return labels\n",
    "\n",
    "def load_features(team_model, dataloader, layer, sensor, device):\n",
    "    features = {}\n",
    "\n",
    "    def get_features(name):\n",
    "        def hook(model, input, output):\n",
    "            features[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    print('Attaching to Layer: ', layer)\n",
    "    selected_layer = getattr(team_model, layer)  #sometimes its just model or model.module\n",
    "    input_features = selected_layer.in_features\n",
    "    handle = selected_layer.register_forward_hook(get_features('feats'))\n",
    "\n",
    "    feats_list = []\n",
    "\n",
    "    # Feed the IQ data into the model\n",
    "    for idx, inputs in tqdm(enumerate(dataloader)):\n",
    "        with torch.inference_mode():\n",
    "            preds = team_model(inputs.to(device))\n",
    "        feats_list.append(features['feats'].cpu().numpy())\n",
    "\n",
    "    feats_list = np.concatenate(feats_list)\n",
    "\n",
    "    features = np.array(feats_list)\n",
    "    features = torch.tensor(features)\n",
    "    features = features.reshape(-1, features.shape[-1])\n",
    "    print(\"features size: \", features.size())\n",
    "    print (type(features))\n",
    "    \n",
    "    handle.remove()\n",
    "    \n",
    "    return features\n",
    "\n",
    "def get_model_accuracy(models_config, combined_tensor, input_path, output_path):\n",
    "    global NUM_CLASSES\n",
    "    \n",
    "    labels_list = []\n",
    "\n",
    "    testloader = load_labels(input_path, models_config['num_batches'])\n",
    "    x = 0\n",
    "    for batch in testloader:\n",
    "        if torch.sum(batch) == 0:\n",
    "            print(f'Found all zeros at index {x}')\n",
    "        \n",
    "        labels_list.append(batch)\n",
    "        x += 1\n",
    "\n",
    "    all_labels = torch.cat(labels_list, dim=0)\n",
    "    labels= all_labels.numpy()\n",
    "\n",
    "    output_artifacts_dir = os.path.join(output_path, 'fusion_data')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(combined_tensor.numpy(), labels, test_size=0.2, random_state=42)\n",
    "    params = {\n",
    "        'objective': 'multi:softmax',  \n",
    "        'num_class': NUM_CLASSES,      \n",
    "        'eval_metric': 'merror',       \n",
    "        'max_depth': 6,                \n",
    "        'min_child_weight': 1,         \n",
    "        'subsample': 0.8,              \n",
    "        'colsample_bytree': 0.8,       \n",
    "        'learning_rate': 0.1,          \n",
    "        'n_estimators': 100            \n",
    "    }\n",
    "\n",
    "    num_rounds = 15  \n",
    "\n",
    "\n",
    "    model_fused = xgb.XGBClassifier(tree_method=\"hist\")\n",
    "    model_fused.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
    "\n",
    "    preds = model_fused.predict(X_test).argmax(1)\n",
    "    acc = (preds == y_test.argmax(1)).sum() / preds.shape[0]\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    model_fused.save_model(f'{output_artifacts_dir}/baseline_fused_2tl.json')\n",
    "\n",
    "def save_features(models_config, num_sensors, output_path):\n",
    "    # Save the extracted features and labels for fusion in other scripts\n",
    "    fusion_data_folder = os.path.join(output_path, 'fusion_data')\n",
    "    os.makedirs(fusion_data_folder, exist_ok=True)\n",
    "\n",
    "    # Save features for the individual models\n",
    "    for sensor in range(1, num_sensors+1):\n",
    "        print(f'Saving model features for model {sensor}')\n",
    "        with open(os.path.join(fusion_data_folder, f'team{sensor}_features_second_to_last.npy'), 'wb') as f:\n",
    "            np.save(f, models_config['team_models'][sensor]['features'].numpy())\n",
    "            \n",
    "    # Save combined features\n",
    "    combined_tensor = torch.cat(([models_config['team_models'][sensor]['features'] for sensor in range(1, num_sensors+1)]), dim=1)\n",
    "    print(f\"Combined_tensor size: {combined_tensor.size()}\")\n",
    "    with open(os.path.join(fusion_data_folder, 'combined_features_allsecond_to_last.npy'), 'wb') as f:\n",
    "        np.save(f, combined_tensor.numpy())\n",
    "\n",
    "    # Save labels\n",
    "    with open(os.path.join(fusion_data_folder, 'labels.npy'), 'wb') as f:\n",
    "        np.save(f, models_config['labels'])\n",
    "        \n",
    "    return combined_tensor\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    args, _ = parse_args()\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print('Using device', device)\n",
    "    \n",
    "    # Load Models\n",
    "    models_config = load_models(args.num_sensors, args.batch_size, args.samples_per_batch, args.input_path, args.model_path, device)\n",
    "\n",
    "    # Save Model Features\n",
    "    combined_tensor = save_features(models_config, args.num_sensors, args.output_path)\n",
    "    \n",
    "    # Evaluate Model Accuracy\n",
    "    get_model_accuracy(models_config, combined_tensor, args.input_path, args.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Testing of File\n",
    "Use the cell below to perform local testing of the file before launching a larger job on SageMaker. Make sure to update the file paths and args depending on the sample data in your local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python ../code/baseline_fusion.py --num-sensors 4 --batch-size 1 --samples-per-batch 10 --input-path \"/root/ClouddRF_Final/cloudd-rf/data/validation\" --output-path \"/root/ClouddRF_Final/cloudd-rf/output\" --model-path \"/root/ClouddRF_Final/cloudd-rf/models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    ")\n",
    "import time \n",
    "\n",
    "timestamp = str(time.time()).split('.')[0]\n",
    "output_prefix = f'{base_job_prefix}/fusion/baseline/outputs/{timestamp}'\n",
    "output_s3_uri = f's3://{default_bucket}/{output_prefix}'\n",
    "code_location = f's3://{default_bucket}/{base_job_prefix}/fusion/baseline/code'\n",
    "\n",
    "# S3 Location of Validation Dataset\n",
    "# UPDATE the var below with the s3 prefix (just the portion after /preprocess) of where the validation data is located\n",
    "s3_validation_data = f's3://{default_bucket}/{base_job_prefix}/preprocess/outputs/1730229830/validation/'\n",
    "\n",
    "# UPDATE the var below with the s3 prefix (just the portion after /training) of where the model is located\n",
    "model_prefix = 'training/pipelines-tjyqyp57lxbd-TrainModel-mSBTy7x3Wh/output/model'\n",
    "s3_model_path = f's3://{default_bucket}/{base_job_prefix}/{model_prefix}'\n",
    "\n",
    "processing_instance_type = \"ml.g5.xlarge\"\n",
    "processing_instance_count = 1\n",
    "env_vars = {\n",
    "    \"SM_CHANNEL_VAL\": \"/opt/ml/processing/input/data/validation\",\n",
    "    \"SM_MODEL_DIR\": \"/opt/ml/processing/model\",\n",
    "    \"SM_OUTPUT_DIR\": \"/opt/ml/processing/output\"\n",
    "}\n",
    "\n",
    "pytorch_processor = PyTorchProcessor(\n",
    "    framework_version='1.13.1',\n",
    "    py_version=\"py39\",\n",
    "    role=role,\n",
    "    env=env_vars,\n",
    "    instance_count=processing_instance_count,\n",
    "    instance_type=processing_instance_type,\n",
    "    base_job_name = f\"{base_job_prefix}-baseline-fusion\",\n",
    "    code_location=code_location\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Processing Script Arguments\n",
    "chunk_size = 1000\n",
    "batch_size = 1\n",
    "num_sensors = 4 # Number of teams with distinct models\n",
    "\n",
    "arguments = [\n",
    "    \"--samples-per-batch\", str(chunk_size), \n",
    "    \"--batch-size\", str(batch_size),\n",
    "    \"--num-sensors\", str(num_sensors)\n",
    "]\n",
    "\n",
    "code = 'baseline_fusion.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pytorch_processor.run(\n",
    "                        code=code,\n",
    "                        source_dir='../code',\n",
    "                        arguments=arguments,\n",
    "                        inputs=[\n",
    "                            ProcessingInput(source=s3_validation_data, destination=env_vars[\"SM_CHANNEL_VAL\"], s3_data_type='S3Prefix', s3_input_mode='File'),\n",
    "                            ProcessingInput(source=s3_model_path, destination=env_vars[\"SM_MODEL_DIR\"], s3_data_type='S3Prefix', s3_input_mode='File'),\n",
    "                       ],\n",
    "                        outputs=[\n",
    "                            ProcessingOutput(source=env_vars[\"SM_OUTPUT_DIR\"], destination = output_s3_uri)\n",
    "                        ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "response = s3_client.list_objects_v2(Bucket=default_bucket, Prefix=output_s3_uri)\n",
    "files = response.get(\"Contents\")\n",
    "\n",
    "for file in files:\n",
    "    print(f\"file_name: {file['Key']}, size: {file['Size']}\")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
