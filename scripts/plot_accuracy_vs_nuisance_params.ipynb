{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation using PyTorch Processor\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Prerequisites](#Prerequisites)\n",
    "3. [Setup](#Setup)\n",
    "4. [Dataset](#Dataset)\n",
    "5. [Build a SageMaker Processing Job](#Build-a-SageMaker-Processing-Job)\n",
    "    1. [Review Model Evaluation Script](#Model-Evaluation-Scripts)\n",
    "    2. [Configure Processing Job](#Configure-Processing-Job)\n",
    "6. [Review Outputs](#Review-Outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Download the notebook into your environment, and you can run it by simply execute each cell in order. To understand what's happening, you'll need:\n",
    "\n",
    "- Familiarity with Python and numpy\n",
    "- Basic familiarity with AWS S3.\n",
    "- Basic understanding of AWS Sagemaker.\n",
    "- Basic familiarity with AWS Command Line Interface (CLI) -- ideally, you should have it set up with credentials to access the AWS account you're running this notebook from.\n",
    "- SageMaker Studio is preferred for the full UI integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Setting up the environment, load the libraries, and define the parameter for the entire notebook.\n",
    "\n",
    "Run the cell below to ensure latest version of SageMaker is installed in your kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install gymnasium\n",
    "!pip3 install xgboost\n",
    "!pip3 install stable-baselines3\n",
    "!pip3 install stable-baselines3[extra]\n",
    "!pip3 install tqdm\n",
    "!pip3 install rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "account = sagemaker_session.account_id()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "base_job_prefix = \"cloudd-rf\"\n",
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a SageMaker Processing Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ../code/plot_accuracy_vs_nuisance_params.py\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "SIG_TYPES = [['2-ASK', ['ask', 2], 0],\n",
    "             ['4-ASK', ['ask', 4], 1],\n",
    "             ['8-ASK', ['ask', 8], 2],\n",
    "             ['BPSK', ['psk', 2], 3],\n",
    "             ['QPSK', ['psk', 4], 4],\n",
    "             ['16-QAM', ['qam', 16], 5],\n",
    "             ['Tone', ['constant'], 6],\n",
    "             ['P-FMCW', ['p_fmcw'], 7]]\n",
    "NUM_CLASSES = len(SIG_TYPES)\n",
    "sig_names = [i[0] for i in SIG_TYPES]\n",
    "\n",
    "OBS_INT = {\n",
    "    'model': 2048,\n",
    "    1: 2048,\n",
    "    2: 1024,\n",
    "    3: 512,\n",
    "    4: 256    \n",
    "}\n",
    "\n",
    "FC_LAYERS = {\n",
    "    1: 'fc3',\n",
    "    2: 'fc1',\n",
    "    3: 'fc3',\n",
    "    4: 'fc2'\n",
    "}\n",
    "\n",
    "def float_list(arg):\n",
    "    return list(map(float, arg.split(',')))\n",
    "\n",
    "def int_list(arg):\n",
    "    return list(map(int, arg.split(',')))\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Number of samples per file.\n",
    "    parser.add_argument(\"--num-sensors\", type=int, default=4)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=1)\n",
    "    parser.add_argument(\"--samples-per-batch\", type=int, default=1000) # CHUNK_SIZE\n",
    "    parser.add_argument(\"--input-path\", type=str, default=os.getenv(\"SM_CHANNEL_VAL\"))\n",
    "    parser.add_argument(\"--output-path\", type=str, default=os.getenv(\"SM_OUTPUT_DIR\"))\n",
    "    parser.add_argument(\"--model-path\", type=str, default=os.getenv(\"SM_BASE_MODEL_DIR\"))\n",
    "    \n",
    "    return parser.parse_known_args()\n",
    "\n",
    "def load_models(num_sensors, batch_size, samples_per_batch, input_path, model_path, device):\n",
    "    print (f\"Loading Models\")\n",
    "    import importlib\n",
    "    models_config = {\n",
    "        'team_models': {},\n",
    "        'fused_models': {\n",
    "            'baseline': {},\n",
    "            'rl': {},\n",
    "            'rfe': {}\n",
    "        }\n",
    "    }\n",
    "    for sensor in range(1, num_sensors+1):\n",
    "        models_config['team_models'][sensor] = {\n",
    "           'model': None,\n",
    "           'dataloader': None,\n",
    "           'params': None,\n",
    "           'features': None\n",
    "        }    \n",
    "    \n",
    "        # Dynamically import each team model class and instantiate model from it\n",
    "        module_name = f'team{sensor}_model'\n",
    "        class_name = f'Team{sensor}Model'\n",
    "        module = importlib.import_module(module_name)\n",
    "        class_ = getattr(module, class_name)\n",
    "        team_model = class_(NUM_CLASSES)\n",
    "        team_model.load_state_dict(torch.load(f'{model_path}/team/team{sensor}_model.pt', map_location=torch.device(device)))\n",
    "        team_model.eval()\n",
    "        team_model.to(device)\n",
    "        print (f\"Loaded Team {sensor} model\")\n",
    "        models_config['team_models'][sensor]['model'] = team_model\n",
    "\n",
    "        # Get the number of trainable parameters in each of the teams' models\n",
    "        team_params = sum(p.numel() for p in team_model.parameters() if p.requires_grad)\n",
    "        print(f'# trainable params, Team {sensor}:', team_model)\n",
    "        models_config['team_models'][sensor]['params'] = team_params\n",
    "    \n",
    "    # Load regular fused model\n",
    "    reg_fused_model = xgb.XGBClassifier(tree_method=\"hist\")\n",
    "    reg_fused_model.load_model(f'{model_path}/baseline/baseline_fused_2tl.json')\n",
    "    models_config['fused_models']['baseline']['model'] = reg_fused_model\n",
    "    print('loaded baseline fused model')\n",
    "\n",
    "    # Load RL fused model\n",
    "    rl_fused_model = xgb.XGBClassifier(tree_method=\"hist\", early_stopping_rounds=2, n_estimators=5)\n",
    "    rl_fused_model.load_model(f'{model_path}/rlrfe/fusion_data/rl_fused_2tl.json')\n",
    "    with open(f'{model_path}/rlrfe/fusion_data/rl_feature_idxes_2tl.pkl', 'rb') as f:\n",
    "        rl_feature_idxes = pickle.load(f)\n",
    "    models_config['fused_models']['rl']['model'] = rl_fused_model\n",
    "    models_config['fused_models']['rl']['feat_idxs'] = rl_feature_idxes\n",
    "    print('loaded RL fused model')\n",
    "\n",
    "    # Load RFE fused model\n",
    "    rfe_fused_model = xgb.XGBClassifier(tree_method=\"hist\", early_stopping_rounds=2)\n",
    "    rfe_fused_model.load_model(f'{model_path}/rlrfe/fusion_data/rfe_fused_2tl.json')\n",
    "    with open(f'{model_path}/rlrfe/fusion_data/rfe_feature_idxes_2tl.pkl', 'rb') as f:\n",
    "        rfe_feature_idxes = pickle.load(f)\n",
    "    models_config['fused_models']['rfe']['model'] = rfe_fused_model\n",
    "    models_config['fused_models']['rfe']['feat_idxs'] = rfe_feature_idxes\n",
    "    print('loaded RFE fused model')\n",
    "    \n",
    "\n",
    "    return models_config\n",
    "\n",
    "def get_num_samples(iq_input_path, samples_per_batch):\n",
    "    joined_files = os.path.join(iq_input_path, \"iqdata\", \"example_*.dat\") \n",
    "    joined_list = glob.glob(joined_files)\n",
    "    num_batches = len(joined_list)\n",
    "    num_samples = num_batches * samples_per_batch\n",
    "    return num_batches, num_samples\n",
    "  \n",
    "def load_data(channel_path, batch_size, num_batches, num_train_examples, data_obs_int):\n",
    "    training_data = np.zeros((num_train_examples, 1, 2, OBS_INT['model']), dtype=np.float32)\n",
    "\n",
    "    last_index = 0\n",
    "    for k in range(num_batches):\n",
    "        # This is used if we have a labeldata folder that stores class labels\n",
    "        label_df = pd.read_csv(f\"{channel_path}/labeldata/example_{k + 1}.csv\")\n",
    "        num_nans = 0\n",
    "        iq_file_name = f\"{channel_path}/iqdata/example_{k + 1}.dat\"\n",
    "        iq_data = np.fromfile(iq_file_name, np.csingle)\n",
    "        iq_data = np.reshape(iq_data, (-1, data_obs_int))  # Turn the IQ data into chunks of (chunk size) x (data_obs_int)\n",
    "        for j in range(iq_data.shape[0]):\n",
    "            # Check if the current row contains NaN values\n",
    "            if np.isnan(np.sum(iq_data[j][:])):    \n",
    "                num_nans += 1\n",
    "            else:\n",
    "                iq_array_norm = iq_data[j][:] / np.max(np.abs(iq_data[j][:]))  # Normalize the observation\n",
    "                iq_array = np.vstack((iq_array_norm.real, iq_array_norm.imag))  # Separate into 2 subarrays - 1 with only real (in-phase), the other only imaginary (quadrature)\n",
    "\n",
    "                # Pad the iq array with zeros to meet the observation length requirement\n",
    "                # This is needed because the CNN models have a fixed input size\n",
    "                iq_array = np.pad(iq_array, ((0, 0), (0, OBS_INT['model'] - iq_array[0].size)), mode='constant', constant_values=0)\n",
    "\n",
    "                training_data[last_index, 0, :, :] = iq_array\n",
    "            last_index += 1\n",
    "        \n",
    "        if num_nans > 0:\n",
    "            print(f'Found {num_nans} rows containing NaNs in {iq_file_name}')\n",
    "    return torch.utils.data.DataLoader([training_data[i] for i in range(num_train_examples)], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def get_sensor_param_dir(sensor, param, input_path):\n",
    "    validation_dir = os.path.join(input_path, str(sensor), param)\n",
    "    root_data_dir = os.listdir(validation_dir)\n",
    "    return validation_dir, root_data_dir\n",
    "\n",
    "def get_dataloader(sensor, param, param_value, input_path, samples_per_batch, batch_size):\n",
    "    validation_dir = os.path.join(input_path, str(sensor), param, str(param_value))\n",
    "    num_batches, num_samples = get_num_samples(validation_dir, samples_per_batch)\n",
    "    dataloader = load_data(validation_dir, batch_size, num_batches, num_samples, OBS_INT[sensor])\n",
    "\n",
    "    return num_batches, dataloader\n",
    "    \n",
    "def load_labels(validation_dir, num_batches):\n",
    "    labels = torch.stack([torch.nn.functional.one_hot(torch.tensor(pd.read_csv(os.path.join(validation_dir, f'labeldata/example_1.csv')).iloc[:,0])) for i in range(num_batches)]).numpy()\n",
    "    labels = labels.reshape((labels.shape[0] * labels.shape[1], labels.shape[2]))\n",
    "    labels = np.argmax(labels, axis=1)\n",
    "    return labels\n",
    "\n",
    "def load_features(team_model, dataloader, layer, device):\n",
    "    features = {}\n",
    "\n",
    "    def get_features(name):\n",
    "        def hook(model, input, output):\n",
    "            features[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    selected_layer = getattr(team_model, layer)  #sometimes its just model or model.module\n",
    "    input_features = selected_layer.in_features\n",
    "    handle = selected_layer.register_forward_hook(get_features('feats'))\n",
    "\n",
    "    feats_list = []\n",
    "\n",
    "    # Feed the IQ data into the model\n",
    "    for idx, inputs in tqdm(enumerate(dataloader)):\n",
    "        with torch.inference_mode():\n",
    "            preds = team_model(inputs.to(device))\n",
    "        feats_list.append(features['feats'].cpu().numpy())\n",
    "\n",
    "    feats_list = np.concatenate(feats_list)\n",
    "\n",
    "    features = np.array(feats_list)\n",
    "    features = torch.tensor(features)\n",
    "    features = features.reshape(-1, features.shape[-1])\n",
    "        \n",
    "    handle.remove()\n",
    "    \n",
    "    return features\n",
    "\n",
    "def get_team_model_accuracy(model, dataloader, labels):\n",
    "    # Get model predictions\n",
    "    outputs = []\n",
    "    with torch.inference_mode():\n",
    "        for idx, inputs in tqdm(enumerate(dataloader)):\n",
    "            pred = np.argmax(model(inputs.to(device)).cpu())\n",
    "            outputs.append(pred)\n",
    "    outputs = np.array(outputs)\n",
    "\n",
    "    # Get the overall accuracy\n",
    "    num_correct = np.sum(outputs == labels)\n",
    "    accuracy = num_correct / len(outputs)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def get_fusion_model_accuracy(models_config, fusion_type, combined_tensor):\n",
    "    \n",
    "    feats = combined_tensor if fusion_type == 'baseline' else combined_tensor[:, models_config['fused_models'][fusion_type]['feat_idxs']]\n",
    "    \n",
    "    preds = models_config['fused_models'][fusion_type]['model'].predict(feats)\n",
    "    if fusion_type == 'baseline': \n",
    "        preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    num_correct = np.sum(preds == models_config['labels'])\n",
    "    accuracy = num_correct / len(preds)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def plot_feature_contribution_over_param(models_config, param, num_sensors, batch_size, samples_per_batch, input_path, output_path, title):\n",
    "    output_artifacts_dir = os.path.join(output_path, 'fusion_plots', 'accuracy_vs_nuisance_params')\n",
    "    os.makedirs(output_artifacts_dir, exist_ok=True)\n",
    "    \n",
    "    # Load the root directory for the current param being evaluated (e.g. snr)\n",
    "    param_dir, param_vals = get_sensor_param_dir(1, param, input_path)\n",
    "    model_accuracies = {}\n",
    "    processed_params = []\n",
    "    for param_val in param_vals:        \n",
    "        for sensor in range(1, num_sensors+1):\n",
    "            print(f'Evaluating model {sensor} accuracy for {param}: {param_val}')\n",
    "            \n",
    "            if (sensor not in model_accuracies):\n",
    "                model_accuracies[sensor] = []\n",
    "            \n",
    "            # Load Labels\n",
    "            curr_sensor_data = os.path.join(param_dir, param_val)\n",
    "            num_batches, num_samples = get_num_samples(curr_sensor_data, samples_per_batch)\n",
    "            models_config['labels'] = load_labels(curr_sensor_data, num_batches)\n",
    "\n",
    "            # Get Dataloader\n",
    "            print (f\"Loading Dataloader for Model {sensor}\")\n",
    "            num_batches, dataloader = get_dataloader(sensor, param, param_val, input_path, samples_per_batch, batch_size)\n",
    "            models_config['team_models'][sensor]['dataloader'] = dataloader\n",
    "        \n",
    "            # Load Features\n",
    "            print (f\"Loading Features for Model {sensor}\")\n",
    "            models_config['team_models'][sensor]['features'] = load_features(models_config['team_models'][sensor]['model'], dataloader, FC_LAYERS[sensor], device)\n",
    "            \n",
    "            # Get Predictions\n",
    "            print(f'Evaluating model {sensor} accuracy')\n",
    "            accuracy = get_team_model_accuracy(models_config['team_models'][sensor]['model'], dataloader, models_config['labels'])\n",
    "            model_accuracies[sensor].append(accuracy)\n",
    "            print(f'Team {sensor} model accuracy for {param}={param_val}:', accuracy)\n",
    "    \n",
    "        combined_tensor = torch.cat(([models_config['team_models'][sensor]['features'] for sensor in range(1, num_sensors+1)]), dim=1)\n",
    "        \n",
    "        # Evaluate Fusion Model Accuracy\n",
    "        for fusion_type in ['baseline','rl','rfe']:\n",
    "            if (fusion_type not in model_accuracies):\n",
    "                model_accuracies[fusion_type] = []\n",
    "            print(f'Evaluating {fusion_type} fusion model accuracy')\n",
    "            \n",
    "            accuracy = get_fusion_model_accuracy(models_config, fusion_type, combined_tensor)\n",
    "            model_accuracies[fusion_type].append(accuracy)\n",
    "            \n",
    "            print(f'{fusion_type} fusion model accuracy for {param}={param_val}:', accuracy)\n",
    "        \n",
    "        # Add current SNR as a processed SNR value\n",
    "        processed_params.append(param_val)\n",
    "\n",
    "    plot_data_dict = {}\n",
    "    plot_data_dict[param] = processed_params\n",
    "    for sensor in range(1, num_sensors+1):\n",
    "        plot_data_dict[f'Team {sensor}']= model_accuracies[sensor]\n",
    "    \n",
    "    df = pd.DataFrame(plot_data_dict)\n",
    "    df.sort_values(by=[param], inplace=True)\n",
    "    df.plot.line(x=param)\n",
    "\n",
    "    plt.ylabel('Average Probability of Correct Classification')\n",
    "    plt.xlabel(title)\n",
    "    plt.title(f'Accuracy vs. {param.upper()}')\n",
    "    plt.savefig(f'{output_artifacts_dir}/{param}_with_fused.png')\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    args, _ = parse_args()\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print('Using device', device)\n",
    "    \n",
    "    # Load Models\n",
    "    models_config = load_models(args.num_sensors, args.batch_size, args.samples_per_batch, args.input_path, args.model_path, device)\n",
    "    \n",
    "    # Plot Accuracies over Nuisance Params\n",
    "    x_axis_labels = {\n",
    "        'snr': 'Signal-to-Noise Ratio (dB)',\n",
    "        'cent_freqs': 'Center Frequency'\n",
    "    }\n",
    "    \n",
    "    for param in ['snr','cent_freqs']:\n",
    "        plot_feature_contribution_over_param(models_config, param, args.num_sensors, args.batch_size, args.samples_per_batch, args.input_path, args.output_path, x_axis_labels[param])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Testing of File\n",
    "Use the cell below to perform local testing of the file before launching a larger job on SageMaker. Make sure to update the file paths and args depending on the sample data in your local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python ../code/plot_accuracy_vs_nuisance_params.py --num-sensors 4 --batch-size 1 --samples-per-batch 100 --input-path \"/root/ClouddRF_Final/cloudd-rf/data/test\" --output-path \"/root/ClouddRF_Final/cloudd-rf/output\" --model-path \"/root/ClouddRF_Final/cloudd-rf/data/models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    ")\n",
    "import time \n",
    "\n",
    "timestamp = str(time.time()).split('.')[0]\n",
    "output_prefix = f'{base_job_prefix}/evaluation/outputs/{timestamp}'\n",
    "output_s3_uri = f's3://{default_bucket}/{output_prefix}'\n",
    "code_location = f's3://{default_bucket}/{base_job_prefix}/evaluation/code'\n",
    "\n",
    "# S3 Location of Validation Dataset\n",
    "# UPDATE the var below with the s3 prefix (just the portion after /preprocess) of where the validation data is located\n",
    "s3_validation_data = f's3://{default_bucket}/{base_job_prefix}/preprocess/outputs/1730252950/validation/'\n",
    "\n",
    "# UPDATE the var below with the s3 prefix (just the portion after /training) of where the team models are located\n",
    "team_model_prefix = 'training/pipelines-pvbseqe6oz4t-TrainModel-lVGjYR0zh2/output/model/'\n",
    "s3_team_model_path = f's3://{default_bucket}/{base_job_prefix}/{team_model_prefix}'\n",
    "\n",
    "# UPDATE the var below with the s3 prefix (just the portion after /training) of where the baseline fusion model is located\n",
    "baseline_fused_model_prefix = 'fusion/baseline/outputs/1730252951/'\n",
    "s3_baseline_model_path = f's3://{default_bucket}/{base_job_prefix}/{baseline_fused_model_prefix}'\n",
    "\n",
    "# UPDATE the var below with the s3 prefix (just the portion after /training) of where the RL-RFE model is located\n",
    "rlrfe_fused_model_prefix = 'fusion/rl_rfe/outputs/1730252951/'\n",
    "s3_rlrfe_model_path = f's3://{default_bucket}/{base_job_prefix}/{rlrfe_fused_model_prefix}'\n",
    "\n",
    "processing_instance_type = \"ml.g5.xlarge\"\n",
    "processing_instance_count = 1\n",
    "env_vars = {\n",
    "    \"SM_CHANNEL_VAL\": \"/opt/ml/processing/input/data/validation\",\n",
    "    \"SM_TEAM_MODEL_DIR\": \"/opt/ml/processing/model/team\",\n",
    "    \"SM_BASELINE_MODEL_DIR\": \"/opt/ml/processing/model/baseline\",\n",
    "    \"SM_RLRFE_MODEL_DIR\": \"/opt/ml/processing/model/rlrfe\",\n",
    "    \"SM_BASE_MODEL_DIR\": \"/opt/ml/processing/model\",\n",
    "    \"SM_OUTPUT_DIR\": \"/opt/ml/processing/output\"\n",
    "}\n",
    "\n",
    "pytorch_processor = PyTorchProcessor(\n",
    "    framework_version='1.13.1',\n",
    "    py_version=\"py39\",\n",
    "    role=role,\n",
    "    env=env_vars,\n",
    "    instance_count=processing_instance_count,\n",
    "    instance_type=processing_instance_type,\n",
    "    base_job_name = f\"{base_job_prefix}-evaluation\",\n",
    "    code_location=code_location\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Processing Script Arguments\n",
    "chunk_size = 100\n",
    "batch_size = 1\n",
    "num_sensors = 4 # Number of teams with distinct models\n",
    "\n",
    "arguments = [\n",
    "    \"--samples-per-batch\", str(chunk_size), \n",
    "    \"--batch-size\", str(batch_size),\n",
    "    \"--num-sensors\", str(num_sensors)\n",
    "]\n",
    "\n",
    "code = 'plot_accuracy_vs_nuisance_params.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pytorch_processor.run(\n",
    "                        code=code,\n",
    "                        source_dir='../code',\n",
    "                        arguments=arguments,\n",
    "                        inputs=[\n",
    "                            ProcessingInput(source=s3_validation_data, destination=env_vars[\"SM_CHANNEL_VAL\"], s3_data_type='S3Prefix'),\n",
    "                            ProcessingInput(source=s3_team_model_path, destination=env_vars[\"SM_TEAM_MODEL_DIR\"], s3_data_type='S3Prefix'),\n",
    "                            ProcessingInput(source=s3_baseline_model_path, destination=env_vars[\"SM_BASELINE_MODEL_DIR\"], s3_data_type='S3Prefix'),\n",
    "                            ProcessingInput(source=s3_rlrfe_model_path, destination=env_vars[\"SM_RLRFE_MODEL_DIR\"], s3_data_type='S3Prefix'),\n",
    "                       ],\n",
    "                        outputs=[\n",
    "                            ProcessingOutput(source=env_vars[\"SM_OUTPUT_DIR\"], destination = output_s3_uri)\n",
    "                        ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "response = s3_client.list_objects_v2(Bucket=default_bucket, Prefix=output_s3_uri)\n",
    "files = response.get(\"Contents\")\n",
    "\n",
    "for file in files:\n",
    "    print(f\"file_name: {file['Key']}, size: {file['Size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.13-gpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
