{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation using PyTorch Processor\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Prerequisites](#Prerequisites)\n",
    "3. [Setup](#Setup)\n",
    "4. [Dataset](#Dataset)\n",
    "5. [Build a SageMaker Processing Job](#Build-a-SageMaker-Processing-Job)\n",
    "    1. [Review Model Evaluation Script](#Model-Evaluation-Scripts)\n",
    "    2. [Configure Processing Job](#Configure-Processing-Job)\n",
    "6. [Review Outputs](#Review-Outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Download the notebook into your environment, and you can run it by simply execute each cell in order. To understand what's happening, you'll need:\n",
    "\n",
    "- Familiarity with Python and numpy\n",
    "- Basic familiarity with AWS S3.\n",
    "- Basic understanding of AWS Sagemaker.\n",
    "- Basic familiarity with AWS Command Line Interface (CLI) -- ideally, you should have it set up with credentials to access the AWS account you're running this notebook from.\n",
    "- SageMaker Studio is preferred for the full UI integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Setting up the environment, load the libraries, and define the parameter for the entire notebook.\n",
    "\n",
    "Run the cell below to ensure latest version of SageMaker is installed in your kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install gymnasium\n",
    "!pip3 install xgboost\n",
    "!pip3 install stable-baselines3\n",
    "!pip3 install stable-baselines3[extra]\n",
    "!pip3 install tqdm\n",
    "!pip3 install rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "account = sagemaker_session.account_id()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "base_job_prefix = \"cloudd-rf\"\n",
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a SageMaker Processing Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../code/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../code/evaluation.py\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "SIG_TYPES = [['2-ASK', ['ask', 2], 0],\n",
    "             ['4-ASK', ['ask', 4], 1],\n",
    "             ['8-ASK', ['ask', 8], 2],\n",
    "             ['BPSK', ['psk', 2], 3],\n",
    "             ['QPSK', ['psk', 4], 4],\n",
    "             ['16-QAM', ['qam', 16], 5],\n",
    "             ['Tone', ['constant'], 6],\n",
    "             ['P-FMCW', ['p_fmcw'], 7]]\n",
    "NUM_CLASSES = len(SIG_TYPES)\n",
    "sig_names = [i[0] for i in SIG_TYPES]\n",
    "\n",
    "OBS_INT = {\n",
    "    'model': 2048,\n",
    "    1: 2048,\n",
    "    2: 1024,\n",
    "    3: 512,\n",
    "    4: 256    \n",
    "}\n",
    "\n",
    "FC_LAYERS = {\n",
    "    1: 'fc3',\n",
    "    2: 'fc1',\n",
    "    3: 'fc3',\n",
    "    4: 'fc2'\n",
    "}\n",
    "\n",
    "def float_list(arg):\n",
    "    return list(map(float, arg.split(',')))\n",
    "\n",
    "def int_list(arg):\n",
    "    return list(map(int, arg.split(',')))\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Number of samples per file.\n",
    "    parser.add_argument(\"--num-sensors\", type=int, default=4)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=1)\n",
    "    parser.add_argument(\"--samples-per-batch\", type=int, default=1000) # CHUNK_SIZE\n",
    "    parser.add_argument(\"--input-path\", type=str, default=os.getenv(\"SM_CHANNEL_VAL\"))\n",
    "    parser.add_argument(\"--output-path\", type=str, default=os.getenv(\"SM_OUTPUT_DIR\"))\n",
    "    parser.add_argument(\"--model-path\", type=str, default=os.getenv(\"SM_BASE_MODEL_DIR\"))\n",
    "    \n",
    "    return parser.parse_known_args()\n",
    "\n",
    "def load_models(num_sensors, batch_size, samples_per_batch, input_path, model_path, device):\n",
    "    global NUM_CLASSES\n",
    "    print (f\"Loading Models\")\n",
    "    import importlib\n",
    "    models_config = {\n",
    "        'team_models': {},\n",
    "        'fused_models': {\n",
    "            'baseline': {},\n",
    "            'rl': {},\n",
    "            'rfe': {}\n",
    "        }\n",
    "    }\n",
    "    for sensor in range(1, num_sensors+1):\n",
    "        models_config['team_models'][sensor] = {\n",
    "           'model': None,\n",
    "           'dataloader': None,\n",
    "           'params': None,\n",
    "           'features': None\n",
    "        }    \n",
    "    \n",
    "        # Dynamically import each team model class and instantiate model from it\n",
    "        module_name = f'team{sensor}_model'\n",
    "        class_name = f'Team{sensor}Model'\n",
    "        module = importlib.import_module(module_name)\n",
    "        class_ = getattr(module, class_name)\n",
    "        team_model = class_(NUM_CLASSES)\n",
    "        team_model.load_state_dict(torch.load(f'{model_path}/team/team{sensor}_model.pt', map_location=torch.device(device)))\n",
    "        team_model.eval()\n",
    "        team_model.to(device)\n",
    "        print (f\"Loaded Team {sensor} model\")\n",
    "        models_config['team_models'][sensor]['model'] = team_model\n",
    "\n",
    "        # Get the number of trainable parameters in each of the teams' models\n",
    "        team_params = sum(p.numel() for p in team_model.parameters() if p.requires_grad)\n",
    "        print(f'# trainable params, Team {sensor}:', team_model)\n",
    "        models_config['team_models'][sensor]['params'] = team_params\n",
    "    \n",
    "        # Get Dataloaders\n",
    "        print (f\"Loading Dataloader for Model {sensor}\")\n",
    "        num_batches, dataloader = get_dataloaders(sensor, input_path, samples_per_batch, batch_size)\n",
    "        models_config['team_models'][sensor]['dataloader'] = dataloader\n",
    "    \n",
    "        # Load Features\n",
    "        print (f\"Loading Features for Model {sensor}\")\n",
    "        models_config['team_models'][sensor]['features'] = load_features(team_model, dataloader, FC_LAYERS[sensor], sensor, device)\n",
    "    \n",
    "    # Load Labels\n",
    "    print (\"Loading Labels\")\n",
    "    models_config['labels'] = load_labels(input_path, num_batches)\n",
    "    \n",
    "    # Load regular fused model\n",
    "    reg_fused_model = xgb.XGBClassifier(tree_method=\"hist\")\n",
    "    reg_fused_model.load_model(f'{model_path}/baseline/fusion_data/baseline_fused_2tl.json')\n",
    "    print('loaded baseline fused model')\n",
    "    models_config['fused_models']['baseline']['model'] = reg_fused_model\n",
    "\n",
    "    # Load RL fused model\n",
    "    rl_fused_model = xgb.XGBClassifier(tree_method=\"hist\", early_stopping_rounds=2, n_estimators=5)\n",
    "    rl_fused_model.load_model(f'{model_path}/rlrfe/fusion_data/rl_fused_2tl.json')\n",
    "    with open(f'{model_path}/rlrfe/fusion_data/rl_feature_idxes_2tl.pkl', 'rb') as f:\n",
    "        rl_feature_idxes = pickle.load(f)\n",
    "    print('loaded RL fused model')\n",
    "    models_config['fused_models']['rl']['model'] = rl_fused_model\n",
    "    models_config['fused_models']['rl']['feat_idxs'] = rl_feature_idxes\n",
    "    #models_config['rl_fused']['model'] = rl_fused_model\n",
    "\n",
    "    # Load RFE fused model\n",
    "    rfe_fused_model = xgb.XGBClassifier(tree_method=\"hist\", early_stopping_rounds=2)\n",
    "    rfe_fused_model.load_model(f'{model_path}/rlrfe/fusion_data/rfe_fused_2tl.json')\n",
    "    with open(f'{model_path}/rlrfe/fusion_data/rfe_feature_idxes_2tl.pkl', 'rb') as f:\n",
    "        rfe_feature_idxes = pickle.load(f)\n",
    "    print('loaded RFE fused model')\n",
    "    models_config['fused_models']['rfe']['model'] = rfe_fused_model\n",
    "    models_config['fused_models']['rfe']['feat_idxs'] = rfe_feature_idxes\n",
    "    return models_config\n",
    "\n",
    "def get_num_samples(iq_input_path, samples_per_batch):\n",
    "    joined_files = os.path.join(iq_input_path, \"iqdata\", \"example_*.dat\") \n",
    "    joined_list = glob.glob(joined_files)\n",
    "    num_batches = len(joined_list)\n",
    "    num_samples = num_batches * samples_per_batch\n",
    "    return num_batches, num_samples\n",
    "  \n",
    "def load_data(channel_path, batch_size, num_batches, num_train_examples, data_obs_int):\n",
    "    training_data = np.zeros((num_train_examples, 1, 2, OBS_INT['model']), dtype=np.float32)\n",
    "\n",
    "    last_index = 0\n",
    "    for k in range(num_batches):\n",
    "        # This is used if we have a labeldata folder that stores class labels\n",
    "        label_df = pd.read_csv(f\"{channel_path}/labeldata/example_{k + 1}.csv\")\n",
    "        num_nans = 0\n",
    "        iq_file_name = f\"{channel_path}/iqdata/example_{k + 1}.dat\"\n",
    "        iq_data = np.fromfile(iq_file_name, np.csingle)\n",
    "        iq_data = np.reshape(iq_data, (-1, data_obs_int))  # Turn the IQ data into chunks of (chunk size) x (data_obs_int)\n",
    "        for j in range(iq_data.shape[0]):\n",
    "            # Check if the current row contains NaN values\n",
    "            if np.isnan(np.sum(iq_data[j][:])):    \n",
    "                num_nans += 1\n",
    "            else:\n",
    "                iq_array_norm = iq_data[j][:] / np.max(np.abs(iq_data[j][:]))  # Normalize the observation\n",
    "                iq_array = np.vstack((iq_array_norm.real, iq_array_norm.imag))  # Separate into 2 subarrays - 1 with only real (in-phase), the other only imaginary (quadrature)\n",
    "\n",
    "                # Pad the iq array with zeros to meet the observation length requirement\n",
    "                # This is needed because the CNN models have a fixed input size\n",
    "                iq_array = np.pad(iq_array, ((0, 0), (0, OBS_INT['model'] - iq_array[0].size)), mode='constant', constant_values=0)\n",
    "\n",
    "                training_data[last_index, 0, :, :] = iq_array\n",
    "            last_index += 1\n",
    "        \n",
    "        if num_nans > 0:\n",
    "            print(f'Found {num_nans} rows containing NaNs in {iq_file_name}')\n",
    "    return torch.utils.data.DataLoader([training_data[i] for i in range(num_train_examples)], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def get_dataloaders(sensor, input_path, samples_per_batch, batch_size):\n",
    "    validation_dir = os.path.join(input_path, str(sensor))\n",
    "    num_batches, num_samples = get_num_samples(validation_dir, samples_per_batch)\n",
    "    dataloader = load_data(validation_dir, batch_size, num_batches, num_samples, OBS_INT[sensor])\n",
    "\n",
    "    return num_batches, dataloader\n",
    "    \n",
    "def load_labels(input_path, num_batches):\n",
    "    validation_dir = os.path.join(input_path, '1')\n",
    "    labels = torch.stack([torch.nn.functional.one_hot(torch.tensor(pd.read_csv(os.path.join(validation_dir, f'labeldata/example_1.csv')).iloc[:,0])) for i in range(num_batches)]).numpy()\n",
    "    labels = labels.reshape((labels.shape[0] * labels.shape[1], labels.shape[2]))\n",
    "    labels = np.argmax(labels, axis=1)\n",
    "    return labels\n",
    "\n",
    "def load_features(team_model, dataloader, layer, sensor, device):\n",
    "    features = {}\n",
    "\n",
    "    def get_features(name):\n",
    "        def hook(model, input, output):\n",
    "            features[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    selected_layer = getattr(team_model, layer)  #sometimes its just model or model.module\n",
    "    input_features = selected_layer.in_features\n",
    "    handle = selected_layer.register_forward_hook(get_features('feats'))\n",
    "\n",
    "    feats_list = []\n",
    "\n",
    "    # Feed the IQ data into the model\n",
    "    for idx, inputs in tqdm(enumerate(dataloader)):\n",
    "        with torch.inference_mode():\n",
    "            preds = team_model(inputs.to(device))\n",
    "        feats_list.append(features['feats'].cpu().numpy())\n",
    "\n",
    "    feats_list = np.concatenate(feats_list)\n",
    "\n",
    "    features = np.array(feats_list)\n",
    "    features = torch.tensor(features)\n",
    "    features = features.reshape(-1, features.shape[-1])\n",
    "    \n",
    "    handle.remove()\n",
    "    \n",
    "    return features\n",
    "\n",
    "def get_team_model_accuracy(models_config, num_sensors, output_path):\n",
    "    global NUM_CLASSES\n",
    "    output_artifacts_dir = os.path.join(output_path, 'fusion_plots', 'confusion_matrices')\n",
    "    os.makedirs(output_artifacts_dir, exist_ok=True)\n",
    "    for sensor in range(1, num_sensors+1):\n",
    "        print(f'Evaluating model {sensor} accuracy')\n",
    "        # Get model predictions\n",
    "        outputs = []\n",
    "        with torch.inference_mode():\n",
    "            for idx, inputs in tqdm(enumerate(models_config['team_models'][sensor]['dataloader'])):\n",
    "                pred = np.argmax(models_config['team_models'][sensor]['model'](inputs.to(device)).cpu())\n",
    "                outputs.append(pred)\n",
    "        outputs = np.array(outputs)\n",
    "        print(outputs.shape)\n",
    "        # Create the confusion matrix\n",
    "        conf_mat = np.zeros((NUM_CLASSES, NUM_CLASSES))\n",
    "        for i in range(outputs.shape[0]):\n",
    "            conf_mat[models_config['labels'][i], outputs[i]] += 1\n",
    "\n",
    "\n",
    "        # Make each row in the confusion matrix sum to 1\n",
    "        for i in range(conf_mat.shape[0]):\n",
    "            conf_mat[i] = conf_mat[i] / np.sum(conf_mat[i])\n",
    "\n",
    "        # Get the overall accuracy\n",
    "        num_correct = np.sum(outputs == models_config['labels'])\n",
    "        accuracy = num_correct / len(outputs)\n",
    "        print(f'Team {sensor} model validation accuracy:', accuracy)\n",
    "\n",
    "        # Set up plot\n",
    "        figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_mat, annot=True, xticklabels=sig_names, yticklabels=sig_names, fmt='.2f')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.title(f'Team {sensor} Model Confusion Matrix')\n",
    "        plt.savefig(f'{output_artifacts_dir}/team{sensor}_confusion_matrix.png')\n",
    "\n",
    "def get_fusion_model_accuracy(models_config, fusion_type, output_path):\n",
    "    global NUM_CLASSES\n",
    "    \n",
    "    print(f'Evaluating {fusion_type} fusion model accuracy')\n",
    "    \n",
    "    output_artifacts_dir = os.path.join(output_path, 'fusion_plots', 'confusion_matrices')\n",
    "    os.makedirs(output_artifacts_dir, exist_ok=True)\n",
    "    \n",
    "    combined_tensor = torch.cat(([models_config['team_models'][sensor]['features'] for sensor in range(1, len(models_config['team_models'])+1)]), dim=1)\n",
    "    \n",
    "    feats = combined_tensor if fusion_type == 'baseline' else combined_tensor[:, models_config['fused_models'][fusion_type]['feat_idxs']]\n",
    "    \n",
    "    preds = models_config['fused_models'][fusion_type]['model'].predict(feats)\n",
    "    if fusion_type == 'baseline': \n",
    "        preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    num_correct = np.sum(preds == models_config['labels'])\n",
    "    accuracy = num_correct / len(preds)\n",
    "    print(f'{fusion_type} fused model validation accuracy:', accuracy)\n",
    "    \n",
    "    conf_mat = np.zeros((NUM_CLASSES, NUM_CLASSES))\n",
    "\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        outputs = models_config['fused_models'][fusion_type]['model'].predict(feats)\n",
    "        if fusion_type == 'baseline': \n",
    "            outputs = np.argmax(outputs, axis=1)\n",
    "\n",
    "        for i in range(outputs.shape[0]):\n",
    "            conf_mat[models_config['labels'][i], outputs[i]] += 1\n",
    "\n",
    "    # Make each row sum to 1\n",
    "    for i in range(conf_mat.shape[0]):\n",
    "        conf_mat[i] = conf_mat[i] / np.sum(conf_mat[i])\n",
    "\n",
    "    figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_mat, annot=True, xticklabels=sig_names, yticklabels=sig_names, fmt='.2f')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title(f'{fusion_type.upper()} Fused Model Confusion Matrix')\n",
    "    plt.savefig(f'{output_artifacts_dir}/{fusion_type}_confusion_matrix.png')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    args, _ = parse_args()\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print('Using device', device)\n",
    "    \n",
    "    # Load Models\n",
    "    models_config = load_models(args.num_sensors, args.batch_size, args.samples_per_batch, args.input_path, args.model_path, device)\n",
    "    \n",
    "    # Evaluate Model Accuracy\n",
    "    get_team_model_accuracy(models_config, args.num_sensors, args.output_path)\n",
    "    \n",
    "    # Evaluate Fusion Model Accuracy\n",
    "    for fusion_type in ['baseline','rl','rfe']:\n",
    "        get_fusion_model_accuracy(models_config, fusion_type, args.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Testing of File\n",
    "Use the cell below to perform local testing of the file before launching a larger job on SageMaker. Make sure to update the file paths and args depending on the sample data in your local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python ../code/evaluation.py --num-sensors 4 --batch-size 1 --samples-per-batch 100 --input-path \"/root/ClouddRF_Final/cloudd-rf/data/validation\" --output-path \"/root/ClouddRF_Final/cloudd-rf/output\" --model-path \"/root/ClouddRF_Final/cloudd-rf/data/models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    ")\n",
    "import time \n",
    "\n",
    "timestamp = str(time.time()).split('.')[0]\n",
    "output_prefix = f'{base_job_prefix}/evaluation/outputs/{timestamp}'\n",
    "output_s3_uri = f's3://{default_bucket}/{output_prefix}'\n",
    "code_location = f's3://{default_bucket}/{base_job_prefix}/evaluation/code'\n",
    "\n",
    "# S3 Location of Validation Dataset\n",
    "# UPDATE the var below with the s3 prefix (just the portion after /preprocess) of where the validation data is located\n",
    "s3_validation_data = f's3://{default_bucket}/{base_job_prefix}/preprocess/outputs/1730252950/validation/'\n",
    "\n",
    "# UPDATE the var below with the s3 prefix (just the portion after /training) of where the team models are located\n",
    "team_model_prefix = 'training/pipelines-pvbseqe6oz4t-TrainModel-lVGjYR0zh2/output/model/'\n",
    "s3_team_model_path = f's3://{default_bucket}/{base_job_prefix}/{team_model_prefix}'\n",
    "\n",
    "# UPDATE the var below with the s3 prefix (just the portion after /training) of where the baseline fusion model is located\n",
    "baseline_fused_model_prefix = 'fusion/baseline/outputs/1730252951/'\n",
    "s3_baseline_model_path = f's3://{default_bucket}/{base_job_prefix}/{baseline_fused_model_prefix}'\n",
    "\n",
    "# UPDATE the var below with the s3 prefix (just the portion after /training) of where the RL-RFE model is located\n",
    "rlrfe_fused_model_prefix = 'fusion/rl_rfe/outputs/1730252951/'\n",
    "s3_rlrfe_model_path = f's3://{default_bucket}/{base_job_prefix}/{rlrfe_fused_model_prefix}'\n",
    "\n",
    "processing_instance_type = \"ml.g5.xlarge\"\n",
    "processing_instance_count = 1\n",
    "env_vars = {\n",
    "    \"SM_CHANNEL_VAL\": \"/opt/ml/processing/input/data/validation\",\n",
    "    \"SM_TEAM_MODEL_DIR\": \"/opt/ml/processing/model/team\",\n",
    "    \"SM_BASELINE_MODEL_DIR\": \"/opt/ml/processing/model/baseline\",\n",
    "    \"SM_RLRFE_MODEL_DIR\": \"/opt/ml/processing/model/rlrfe\",\n",
    "    \"SM_BASE_MODEL_DIR\": \"/opt/ml/processing/model\",\n",
    "    \"SM_OUTPUT_DIR\": \"/opt/ml/processing/output\"\n",
    "}\n",
    "\n",
    "pytorch_processor = PyTorchProcessor(\n",
    "    framework_version='1.13.1',\n",
    "    py_version=\"py39\",\n",
    "    role=role,\n",
    "    env=env_vars,\n",
    "    instance_count=processing_instance_count,\n",
    "    instance_type=processing_instance_type,\n",
    "    base_job_name = f\"{base_job_prefix}-evaluation\",\n",
    "    code_location=code_location\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Processing Script Arguments\n",
    "chunk_size = 100\n",
    "batch_size = 1\n",
    "num_sensors = 4 # Number of teams with distinct models\n",
    "\n",
    "arguments = [\n",
    "    \"--samples-per-batch\", str(chunk_size), \n",
    "    \"--batch-size\", str(batch_size),\n",
    "    \"--num-sensors\", str(num_sensors)\n",
    "]\n",
    "\n",
    "code = 'evaluation.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pytorch_processor.run(\n",
    "                        code=code,\n",
    "                        source_dir='../code',\n",
    "                        arguments=arguments,\n",
    "                        inputs=[\n",
    "                            ProcessingInput(source=s3_validation_data, destination=env_vars[\"SM_CHANNEL_VAL\"], s3_data_type='S3Prefix'),\n",
    "                            ProcessingInput(source=s3_team_model_path, destination=env_vars[\"SM_TEAM_MODEL_DIR\"], s3_data_type='S3Prefix'),\n",
    "                            ProcessingInput(source=s3_baseline_model_path, destination=env_vars[\"SM_BASELINE_MODEL_DIR\"], s3_data_type='S3Prefix'),\n",
    "                            ProcessingInput(source=s3_rlrfe_model_path, destination=env_vars[\"SM_RLRFE_MODEL_DIR\"], s3_data_type='S3Prefix'),\n",
    "                       ],\n",
    "                        outputs=[\n",
    "                            ProcessingOutput(source=env_vars[\"SM_OUTPUT_DIR\"], destination = output_s3_uri)\n",
    "                        ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "response = s3_client.list_objects_v2(Bucket=default_bucket, Prefix=output_s3_uri)\n",
    "files = response.get(\"Contents\")\n",
    "\n",
    "for file in files:\n",
    "    print(f\"file_name: {file['Key']}, size: {file['Size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.13-gpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
