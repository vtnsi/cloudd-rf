{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Contribution Analysis using PyTorch Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a SageMaker Processing Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Contribution Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ../code/feature_contribution.py\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "from random import sample\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "SIG_TYPES = [['2-ASK', ['ask', 2], 0],\n",
    "             ['4-ASK', ['ask', 4], 1],\n",
    "             ['8-ASK', ['ask', 8], 2],\n",
    "             ['BPSK', ['psk', 2], 3],\n",
    "             ['QPSK', ['psk', 4], 4],\n",
    "             ['16-QAM', ['qam', 16], 5],\n",
    "             ['Tone', ['constant'], 6],\n",
    "             ['P-FMCW', ['p_fmcw'], 7]]\n",
    "NUM_CLASSES = len(SIG_TYPES)\n",
    "sig_names = [i[0] for i in SIG_TYPES]\n",
    "\n",
    "OBS_INT = {\n",
    "    'model': 2048,\n",
    "    1: 2048,\n",
    "    2: 1024,\n",
    "    3: 512,\n",
    "    4: 256    \n",
    "}\n",
    "\n",
    "FC_LAYERS = {\n",
    "    1: 'fc3',\n",
    "    2: 'fc1',\n",
    "    3: 'fc3',\n",
    "    4: 'fc2'\n",
    "}\n",
    "\n",
    "def float_list(arg):\n",
    "    return list(map(float, arg.split(',')))\n",
    "\n",
    "def int_list(arg):\n",
    "    return list(map(int, arg.split(',')))\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Number of samples per file.\n",
    "    parser.add_argument(\"--num-sensors\", type=int, default=4)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=1)\n",
    "    parser.add_argument(\"--samples-per-batch\", type=int, default=1000) # CHUNK_SIZE\n",
    "    parser.add_argument(\"--input-path\", type=str, default=os.getenv(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--output-path\", type=str, default=os.getenv(\"SM_OUTPUT_DIR\"))\n",
    "    parser.add_argument(\"--model-path\", type=str, default=os.getenv(\"SM_MODEL_DIR\"))\n",
    "    \n",
    "    return parser.parse_known_args()\n",
    "\n",
    "def load_models(num_sensors, batch_size, samples_per_batch, input_path, model_path, device):\n",
    "    global NUM_CLASSES\n",
    "    print (f\"Loading Models\")\n",
    "    import importlib\n",
    "    models_config = {\n",
    "        'team_models': {}\n",
    "    }\n",
    "    for sensor in range(1, num_sensors+1):\n",
    "        models_config['team_models'][sensor] = {\n",
    "           'model': None,\n",
    "           'dataloader': None,\n",
    "           'params': None,\n",
    "           'importance': None,\n",
    "           'features': None\n",
    "        }\n",
    "        # Dynamically import each team model class and instantiate model from it\n",
    "        module_name = f'team{sensor}_model'\n",
    "        class_name = f'Team{sensor}Model'\n",
    "        module = importlib.import_module(module_name)\n",
    "        class_ = getattr(module, class_name)\n",
    "        team_model = class_(NUM_CLASSES)\n",
    "        team_model.load_state_dict(torch.load(f'{model_path}/team{sensor}_model.pt', map_location=torch.device(device)))\n",
    "        team_model.eval()\n",
    "        team_model.to(device)\n",
    "        print (f\"Loaded Team {sensor} model\")\n",
    "        models_config['team_models'][sensor]['model'] = team_model\n",
    "\n",
    "        # Get the number of trainable parameters in each of the teams' models\n",
    "        team_params = sum(p.numel() for p in team_model.parameters() if p.requires_grad)\n",
    "        models_config['team_models'][sensor]['params'] = team_params\n",
    "\n",
    "    return models_config\n",
    "\n",
    "def get_num_samples(iq_input_path, samples_per_batch):\n",
    "    joined_files = os.path.join(iq_input_path, \"iqdata\", \"example_*.dat\") \n",
    "    joined_list = glob.glob(joined_files)\n",
    "    num_batches = len(joined_list)\n",
    "    num_samples = num_batches * samples_per_batch\n",
    "    return num_batches, num_samples\n",
    "  \n",
    "def load_data(channel_path, batch_size, num_batches, num_train_examples, data_obs_int):\n",
    "    training_data = np.zeros((num_train_examples, 1, 2, OBS_INT['model']), dtype=np.float32)\n",
    "\n",
    "    last_index = 0\n",
    "    for k in range(num_batches):\n",
    "        # This is used if we have a labeldata folder that stores class labels\n",
    "        label_df = pd.read_csv(f\"{channel_path}/labeldata/example_{k + 1}.csv\")\n",
    "        num_nans = 0\n",
    "        iq_file_name = f\"{channel_path}/iqdata/example_{k + 1}.dat\"\n",
    "        iq_data = np.fromfile(iq_file_name, np.csingle)\n",
    "        iq_data = np.reshape(iq_data, (-1, data_obs_int))  # Turn the IQ data into chunks of (chunk size) x (data_obs_int)\n",
    "        for j in range(iq_data.shape[0]):\n",
    "            # Check if the current row contains NaN values\n",
    "            if np.isnan(np.sum(iq_data[j][:])):    \n",
    "                num_nans += 1\n",
    "            else:\n",
    "                iq_array_norm = iq_data[j][:] / np.max(np.abs(iq_data[j][:]))  # Normalize the observation\n",
    "                iq_array = np.vstack((iq_array_norm.real, iq_array_norm.imag))  # Separate into 2 subarrays - 1 with only real (in-phase), the other only imaginary (quadrature)\n",
    "\n",
    "                # Pad the iq array with zeros to meet the observation length requirement\n",
    "                # This is needed because the CNN models have a fixed input size\n",
    "                iq_array = np.pad(iq_array, ((0, 0), (0, OBS_INT['model'] - iq_array[0].size)), mode='constant', constant_values=0)\n",
    "\n",
    "                training_data[last_index, 0, :, :] = iq_array\n",
    "            last_index += 1\n",
    "        \n",
    "        if num_nans > 0:\n",
    "            print(f'Found {num_nans} rows containing NaNs in {iq_file_name}')\n",
    "    return torch.utils.data.DataLoader([training_data[i] for i in range(num_train_examples)], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def get_sensor_param_dir(sensor, param, input_path):\n",
    "    validation_dir = os.path.join(input_path, str(sensor), param)\n",
    "    root_data_dir = os.listdir(validation_dir)\n",
    "    return validation_dir, root_data_dir\n",
    "\n",
    "def get_dataloader(sensor, param, param_value, input_path, samples_per_batch, batch_size):\n",
    "    validation_dir = os.path.join(input_path, str(sensor), param, str(param_value))\n",
    "    num_batches, num_samples = get_num_samples(validation_dir, samples_per_batch)\n",
    "    dataloader = load_data(validation_dir, batch_size, num_batches, num_samples, OBS_INT[sensor])\n",
    "\n",
    "    return num_batches, dataloader\n",
    "    \n",
    "def load_labels(validation_dir, num_batches):\n",
    "    labels = torch.stack([torch.nn.functional.one_hot(torch.tensor(pd.read_csv(os.path.join(validation_dir, f'labeldata/example_1.csv')).iloc[:,0])) for i in range(num_batches)]).numpy()\n",
    "    labels = labels.reshape((labels.shape[0] * labels.shape[1], labels.shape[2]))\n",
    "    labels = np.argmax(labels, axis=1)\n",
    "    return labels\n",
    "\n",
    "def load_features(team_model, dataloader, layer, device):\n",
    "    features = {}\n",
    "\n",
    "    def get_features(name):\n",
    "        def hook(model, input, output):\n",
    "            features[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    selected_layer = getattr(team_model, layer)  #sometimes its just model or model.module\n",
    "    input_features = selected_layer.in_features\n",
    "    handle = selected_layer.register_forward_hook(get_features('feats'))\n",
    "\n",
    "    feats_list = []\n",
    "\n",
    "    # Feed the IQ data into the model\n",
    "    for idx, inputs in tqdm(enumerate(dataloader)):\n",
    "        with torch.inference_mode():\n",
    "            preds = team_model(inputs.to(device))\n",
    "        feats_list.append(features['feats'].cpu().numpy())\n",
    "\n",
    "    feats_list = np.concatenate(feats_list)\n",
    "\n",
    "    features = np.array(feats_list)\n",
    "    features = torch.tensor(features)\n",
    "    features = features.reshape(-1, features.shape[-1])\n",
    "        \n",
    "    handle.remove()\n",
    "    \n",
    "    return features\n",
    "\n",
    "def plot_feature_contribution_over_param(models_config, param, num_sensors, batch_size, samples_per_batch, input_path, output_path, title):\n",
    "    output_artifacts_dir = os.path.join(output_path, 'fusion_plots', 'feature_importances')\n",
    "    os.makedirs(output_artifacts_dir, exist_ok=True)\n",
    "    \n",
    "    # Load the root directory for the current param being evaluated (e.g. snr)\n",
    "    param_dir, param_vals = get_sensor_param_dir(1, param, input_path)\n",
    "    importances_data = {}\n",
    "    processed_params = []\n",
    "    NUM_ITERATIONS=10\n",
    "    for param_val in param_vals:\n",
    "        for sensor in range(1, num_sensors+1):\n",
    "            print(f'Evaluating model {sensor} feature importance for {param}: {param_val}')\n",
    "\n",
    "            # Load Labels\n",
    "            curr_sensor_data = os.path.join(param_dir, param_val)\n",
    "            num_batches, num_samples = get_num_samples(curr_sensor_data, samples_per_batch)\n",
    "            models_config['labels'] = load_labels(curr_sensor_data, num_batches)\n",
    "\n",
    "            # Get model predictions\n",
    "            if (sensor not in importances_data):\n",
    "                importances_data[sensor] = {\n",
    "                    'importances': 0,\n",
    "                    'avg': []\n",
    "                }\n",
    "            \n",
    "            importances_data[sensor]['importances'] = 0    \n",
    "            \n",
    "            # Get Dataloader\n",
    "            print (f\"Loading Dataloader for Model {sensor}\")\n",
    "            num_batches, dataloader = get_dataloader(sensor, param, param_val, input_path, samples_per_batch, batch_size)\n",
    "            models_config['team_models'][sensor]['dataloader'] = dataloader\n",
    "        \n",
    "            # Load Features\n",
    "            print (f\"Loading Features for Model {sensor}\")\n",
    "            models_config['team_models'][sensor]['features'] = load_features(models_config['team_models'][sensor]['model'], dataloader, FC_LAYERS[sensor], device)\n",
    "    \n",
    "        combined_tensor = torch.cat(([models_config['team_models'][sensor]['features'] for sensor in range(1, num_sensors+1)]), dim=1)\n",
    "        \n",
    "        # Note: Decision tree classifiers use a stochastic algorithm so we take model importance as the average over multiple iterations\n",
    "        for i in tqdm(range(NUM_ITERATIONS), desc='Getting model importances'):\n",
    "            model = DecisionTreeClassifier()\n",
    "            model.fit(combined_tensor, models_config['labels'])\n",
    "            importances = model.feature_importances_\n",
    "            importances = np.array(importances)\n",
    "            \n",
    "            last_index = 0\n",
    "            next_index = 0\n",
    "            for sensor in range(1, num_sensors+1):\n",
    "                next_index = models_config['team_models'][sensor]['features'].size()[1] if sensor < num_sensors else len(importances)\n",
    "                importances_data[sensor]['importances'] += np.sum(importances[last_index:next_index])\n",
    "                last_index += models_config['team_models'][sensor]['features'].size()[1]\n",
    "        \n",
    "        importances_sum = 0\n",
    "        for sensor in range(1, num_sensors+1):\n",
    "            avg_importance = importances_data[sensor]['importances']/NUM_ITERATIONS\n",
    "            importances_data[sensor]['avg'].append(avg_importance)\n",
    "            importances_sum += avg_importance\n",
    "        \n",
    "        if not math.isclose(1.0, importances_sum, abs_tol=0.01):\n",
    "            print(f'Error: Importances do not sum to 1.0 (Was {importances_sum})')\n",
    "\n",
    "        # Add current SNR as a processed SNR value\n",
    "        processed_params.append(param_val)\n",
    "    print(importances_data)\n",
    "    plot_data_dict = {}\n",
    "    plot_data_dict[param] = processed_params\n",
    "    for sensor in range(1, num_sensors+1):\n",
    "        plot_data_dict[f'Team {sensor}']= importances_data[sensor]['avg']\n",
    "    \n",
    "    df = pd.DataFrame(plot_data_dict)\n",
    "    df.sort_values(by=[param], inplace=True)\n",
    "    df.plot.line(x=param)\n",
    "\n",
    "    plt.ylabel('Average Feature Importance')\n",
    "    plt.xlabel(title)\n",
    "    plt.title(f'Average Feature Importance vs. {title}, All Models')\n",
    "    plt.savefig(f'{output_artifacts_dir}/avg_feat_importance_{param}.png')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    args, _ = parse_args()\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print('Using device', device)\n",
    "    \n",
    "    # Load Models\n",
    "    models_config = load_models(args.num_sensors, args.batch_size, args.samples_per_batch, args.input_path, args.model_path, device)\n",
    "    \n",
    "    x_axis_labels = {\n",
    "        'snr': 'Signal-to-Noise Ratio (dB)',\n",
    "        'cent_freqs': 'Center Frequency'\n",
    "    }\n",
    "    \n",
    "    for param in ['snr','cent_freqs']:\n",
    "        plot_feature_contribution_over_param(models_config, param, args.num_sensors, args.batch_size, args.samples_per_batch, args.input_path, args.output_path, x_axis_labels[param])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Testing of File\n",
    "Use the cell below to perform local testing of the file before launching a larger job on SageMaker. Make sure to update the file paths and args depending on the sample data in your local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install xgboost\n",
    "!pip3 install tqdm\n",
    "!pip3 install rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Loading Models\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "Loaded Team 1 model\n",
      "Loaded Team 2 model\n",
      "Loaded Team 3 model\n",
      "Loaded Team 4 model\n",
      "Evaluating model 1 feature importance for snr: 2\n",
      "Loading Dataloader for Model 1\n",
      "Loading Features for Model 1\n",
      "INFO:root:Using NamedTuple = typing._NamedTuple instead.\n",
      "[2024-10-31 03:55:28.447 pytorch-1-13-gpu-py-ml-g4dn-xlarge-527e33c924f34a0c20ebf51c5b64:1499 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2024-10-31 03:55:28.479 pytorch-1-13-gpu-py-ml-g4dn-xlarge-527e33c924f34a0c20ebf51c5b64:1499 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "2000it [00:04, 473.65it/s]\n",
      "Evaluating model 2 feature importance for snr: 2\n",
      "Loading Dataloader for Model 2\n",
      "Loading Features for Model 2\n",
      "2000it [00:02, 701.88it/s]\n",
      "Evaluating model 3 feature importance for snr: 2\n",
      "Loading Dataloader for Model 3\n",
      "Loading Features for Model 3\n",
      "0it [00:00, ?it/s]/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "2000it [00:01, 1211.50it/s]\n",
      "Evaluating model 4 feature importance for snr: 2\n",
      "Loading Dataloader for Model 4\n",
      "Loading Features for Model 4\n",
      "2000it [00:02, 698.67it/s]\n",
      "Getting model importances: 100%|████████████████| 10/10 [00:21<00:00,  2.17s/it]\n",
      "Error: Importances do not sum to 1.0 (Was 0.8954572431588702)\n",
      "Evaluating model 1 feature importance for snr: 0\n",
      "Loading Dataloader for Model 1\n",
      "Loading Features for Model 1\n",
      "2000it [00:02, 715.46it/s]\n",
      "Evaluating model 2 feature importance for snr: 0\n",
      "Loading Dataloader for Model 2\n",
      "Loading Features for Model 2\n",
      "2000it [00:02, 755.85it/s]\n",
      "Evaluating model 3 feature importance for snr: 0\n",
      "Loading Dataloader for Model 3\n",
      "Loading Features for Model 3\n",
      "0it [00:00, ?it/s]/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "2000it [00:01, 1440.87it/s]\n",
      "Evaluating model 4 feature importance for snr: 0\n",
      "Loading Dataloader for Model 4\n",
      "Loading Features for Model 4\n",
      "2000it [00:03, 651.13it/s]\n",
      "Getting model importances: 100%|████████████████| 10/10 [00:21<00:00,  2.11s/it]\n",
      "Error: Importances do not sum to 1.0 (Was 0.8970625545357042)\n",
      "Evaluating model 1 feature importance for snr: 8\n",
      "Loading Dataloader for Model 1\n",
      "Loading Features for Model 1\n",
      "2000it [00:02, 730.95it/s]\n",
      "Evaluating model 2 feature importance for snr: 8\n",
      "Loading Dataloader for Model 2\n",
      "Loading Features for Model 2\n",
      "2000it [00:02, 775.82it/s]\n",
      "Evaluating model 3 feature importance for snr: 8\n",
      "Loading Dataloader for Model 3\n",
      "Loading Features for Model 3\n",
      "0it [00:00, ?it/s]/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "2000it [00:01, 1432.54it/s]\n",
      "Evaluating model 4 feature importance for snr: 8\n",
      "Loading Dataloader for Model 4\n",
      "Loading Features for Model 4\n",
      "2000it [00:02, 683.92it/s]\n",
      "Getting model importances: 100%|████████████████| 10/10 [00:27<00:00,  2.76s/it]\n",
      "Error: Importances do not sum to 1.0 (Was 0.8839421150929982)\n",
      "{1: {'importances': 0.9383789441723203, 'avg': [0.07533688825844007, 0.10069093778160107, 0.09383789441723203]}, 2: {'importances': 7.901042206757662, 'avg': [0.8201203549004301, 0.7963716167541031, 0.7901042206757662]}, 3: {'importances': 0.0, 'avg': [0.0, 0.0, 0.0]}, 4: {'importances': 0.0, 'avg': [0.0, 0.0, 0.0]}}\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "!python ../code/feature_contribution.py --num-sensors 4 --batch-size 1 --samples-per-batch 100 --input-path \"/root/ClouddRF_Final/cloudd-rf/data/test\" --output-path \"/root/ClouddRF_Final/cloudd-rf/output\" --model-path \"/root/ClouddRF_Final/cloudd-rf/models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Setting up the environment, load the libraries, and define the parameter for the entire notebook.\n",
    "\n",
    "Run the cell below to ensure latest version of SageMaker is installed in your kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "account = sagemaker_session.account_id()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "base_job_prefix = \"cloudd-rf\"\n",
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    ")\n",
    "import time \n",
    "\n",
    "timestamp = str(time.time()).split('.')[0]\n",
    "output_prefix = f'{base_job_prefix}/evaluation/outputs/{timestamp}'\n",
    "output_s3_uri = f's3://{default_bucket}/{output_prefix}'\n",
    "code_location = f's3://{default_bucket}/{base_job_prefix}/evaluation/code'\n",
    "\n",
    "# S3 Location of Validation Dataset\n",
    "# UPDATE the var below with the s3 prefix (just the portion after /preprocess) of where the validation data is located\n",
    "s3_test_data = f's3://{default_bucket}/{base_job_prefix}/preprocess/outputs/1730252950/test/'\n",
    "\n",
    "# UPDATE the var below with the s3 prefix (just the portion after /training) of where the team models are located\n",
    "team_model_prefix = 'training/pipelines-pvbseqe6oz4t-TrainModel-lVGjYR0zh2/output/model/'\n",
    "s3_team_model_path = f's3://{default_bucket}/{base_job_prefix}/{team_model_prefix}'\n",
    "\n",
    "processing_instance_type = \"ml.g5.xlarge\"\n",
    "processing_instance_count = 1\n",
    "env_vars = {\n",
    "    \"SM_CHANNEL_TEST\": \"/opt/ml/processing/input/data/test\",\n",
    "    \"SM_MODEL_DIR\": \"/opt/ml/processing/model\",\n",
    "    \"SM_OUTPUT_DIR\": \"/opt/ml/processing/output\"\n",
    "}\n",
    "\n",
    "pytorch_processor = PyTorchProcessor(\n",
    "    framework_version='1.13.1',\n",
    "    py_version=\"py39\",\n",
    "    role=role,\n",
    "    env=env_vars,\n",
    "    instance_count=processing_instance_count,\n",
    "    instance_type=processing_instance_type,\n",
    "    base_job_name = f\"{base_job_prefix}-feature-contribution\",\n",
    "    code_location=code_location\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Processing Script Arguments\n",
    "chunk_size = 100\n",
    "batch_size = 1\n",
    "num_sensors = 4 # Number of teams with distinct models\n",
    "\n",
    "arguments = [\n",
    "    \"--samples-per-batch\", str(chunk_size), \n",
    "    \"--batch-size\", str(batch_size),\n",
    "    \"--num-sensors\", str(num_sensors)\n",
    "]\n",
    "\n",
    "code = 'feature_contribution.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name cloudd-rf-evaluation-2024-10-31-04-03-38-609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................"
     ]
    }
   ],
   "source": [
    "pytorch_processor.run(\n",
    "                        code=code,\n",
    "                        source_dir='../code',\n",
    "                        arguments=arguments,\n",
    "                        inputs=[\n",
    "                            ProcessingInput(source=s3_test_data, destination=env_vars[\"SM_CHANNEL_TEST\"], s3_data_type='S3Prefix'),\n",
    "                            ProcessingInput(source=s3_team_model_path, destination=env_vars[\"SM_MODEL_DIR\"], s3_data_type='S3Prefix')\n",
    "                       ],\n",
    "                        outputs=[\n",
    "                            ProcessingOutput(source=env_vars[\"SM_OUTPUT_DIR\"], destination = output_s3_uri)\n",
    "                        ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "response = s3_client.list_objects_v2(Bucket=default_bucket, Prefix=output_s3_uri)\n",
    "files = response.get(\"Contents\")\n",
    "\n",
    "for file in files:\n",
    "    print(f\"file_name: {file['Key']}, size: {file['Size']}\")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.13-gpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
