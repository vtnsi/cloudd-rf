{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0308f35a-cfa6-4529-9aa4-f1eaeea961ac",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af2accfd-c05d-4905-b254-8117d203c8f3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#!pip install xgboost\n",
    "#!pip install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --user\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "#os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f3f3623-ed52-4247-88c1-4b4cf4e65dba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Team1Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(2, 16))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=(1, 8))\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(1, 8))\n",
    "        #self.fc1 = nn.Linear(in_features=15360, out_features=1200)  # Fully Connected Layer\n",
    "        self.fc1 = nn.LazyLinear(out_features=1200)\n",
    "        self.fc2 = nn.Linear(in_features=1200, out_features=100)\n",
    "        self.fc3 = nn.Linear(in_features=100, out_features=65)\n",
    "        self.fc4 = nn.Linear(in_features=65, out_features=self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # print(f'after conv1: {x.shape}')\n",
    "        x = self.pool(x)\n",
    "        # print(f'after pool: {x.shape}')\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # print(f'after conv2: {x.shape}')\n",
    "        x = self.pool(x)\n",
    "        # print(f'after pool: {x.shape}')\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # print(f'after conv3: {x.shape}')\n",
    "        x = self.pool(x)\n",
    "        # print(f'after pool: {x.shape}')\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        # print(f'after reshaping: {x.shape}')\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # print(f'fc1: {x.shape}')\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # print(f'fc2: {x.shape}')\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # print(f'fc3: {x.shape}')\n",
    "        #x = F.relu(self.fc4(x))\n",
    "        x = self.fc4(x)\n",
    "        # print(f'fc3: {x.shape}')\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00d85a70-f677-4370-8ada-eb6bbf8474ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Team2Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(2, 128, 8, dtype=torch.float32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Conv1d(128, 256, 8, dtype=torch.float32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Conv1d(256, 512, 8, dtype=torch.float32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Conv1d(512, 1024, 8, dtype=torch.float32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.BatchNorm1d(1024),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.LazyLinear(512, dtype=torch.float32)\n",
    "        self.fc2 = nn.Linear(512, num_classes, dtype=torch.float32)\n",
    "        # self.fc = nn.Sequential(\n",
    "        #     nn.LazyLinear(512, dtype=torch.float32),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(512, num_classes, dtype=torch.float32),\n",
    "        #     nn.ReLU(),\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        x = x.flatten(1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        #return F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "868d6d5e-d8bc-4f48-84fc-bcec681c5eed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# From headley_modrec.py\n",
    "class Team3Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 16, (2, 16))\n",
    "        self.conv2 = nn.Conv2d(16, 8, (1, 8))\n",
    "        self.conv3 = nn.Conv2d(8, 4, (1, 4))\n",
    "        #self.fc1 = nn.Linear(3996, 512)\n",
    "        self.fc1 = nn.LazyLinear(out_features=512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, self.num_classes)\n",
    "\n",
    "        self.activation = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        x = F.tanh(self.conv2(x))\n",
    "        x = F.tanh(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a4d189-1cff-4241-9136-e67cac8243ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Team4Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.re1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.re2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.re3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.re4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        #self.fc1 = nn.Linear(128 * 256,512)  # I dont exactly know why it is 128x256, but I had to do some debugging and hardcode the required value\n",
    "        self.fc1 = nn.LazyLinear(out_features=512)\n",
    "\n",
    "        self.re5 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.re6 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.re1(self.conv1(x)))\n",
    "        x = self.pool2(self.re2(self.conv2(x)))\n",
    "        x = self.pool3(self.re3(self.conv3(x)))\n",
    "        x = self.pool4(self.re4(self.conv4(x)))\n",
    "        x = self.flat(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.re5(self.fc1(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.re6(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72060951-8ee4-4a69-89f4-6f2763630727",
   "metadata": {},
   "source": [
    "## Loading models and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f501207-cb88-47cf-ae8e-cf00255d5ace",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "loaded team1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3623/2531680920.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  team1_model.load_state_dict(torch.load('../data/summer_models/team1_model.pt', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_3623/2531680920.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  team2_model.load_state_dict(torch.load('../data/summer_models/team2_model.pt', map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded team2\n",
      "loaded team3\n",
      "loaded team4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3623/2531680920.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  team3_model.load_state_dict(torch.load('../data/summer_models/team3_model.pt', map_location=torch.device('cpu')))\n",
      "/tmp/ipykernel_3623/2531680920.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  team4_model.load_state_dict(torch.load('../data/summer_models/team4_model.pt', map_location=torch.device('cpu')))\n"
     ]
    }
   ],
   "source": [
    "sig_types = [['2-ASK', ['ask', 2], 0],\n",
    "             ['4-ASK', ['ask', 4], 1],\n",
    "             ['8-ASK', ['ask', 8], 2],\n",
    "             ['BPSK', ['psk', 2], 3],\n",
    "             ['QPSK', ['psk', 4], 4],\n",
    "             ['16-QAM', ['qam', 16], 5],\n",
    "             ['Tone', ['constant'], 6],\n",
    "             ['P-FMCW', ['p_fmcw'], 7]]\n",
    "num_classes = len(sig_types)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "team1_model = Team1Model(num_classes)\n",
    "team1_model.load_state_dict(torch.load('../data/summer_models/team1_model.pt', map_location=torch.device('cpu')))\n",
    "team1_model.eval()\n",
    "team1_model.to(device)\n",
    "print (\"loaded team1\")\n",
    "\n",
    "team2_model = Team2Model(num_classes)\n",
    "team2_model.load_state_dict(torch.load('../data/summer_models/team2_model.pt', map_location=torch.device('cpu')))\n",
    "team2_model.eval()\n",
    "team2_model.to(device)\n",
    "print (\"loaded team2\")\n",
    "team3_model = Team3Model(num_classes)\n",
    "team3_model.load_state_dict(torch.load('../data/summer_models/team3_model.pt', map_location=torch.device('cpu')))\n",
    "team3_model.eval()\n",
    "team3_model.to(device)\n",
    "print (\"loaded team3\")\n",
    "team4_model = Team4Model(num_classes)\n",
    "team4_model.load_state_dict(torch.load('../data/summer_models/team4_model.pt', map_location=torch.device('cpu')))\n",
    "team4_model.eval()\n",
    "team4_model.to(device)\n",
    "print (\"loaded team4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b48f649-995f-4415-a1e5-2e75176b03b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODELS_OBS_INT = 2048\n",
    "def load_data(channel_path, batch_size, num_batches, num_train_examples, data_obs_int):\n",
    "    training_data = np.zeros((num_train_examples, 1, 2, MODELS_OBS_INT), dtype=np.float32)\n",
    "\n",
    "    last_index = 0\n",
    "    for k in range(num_batches):\n",
    "        # This is used if we have a labeldata folder that stores class labels\n",
    "        label_df = pd.read_csv(f\"{channel_path}/labeldata/example_{k + 1}.csv\")\n",
    "\n",
    "        iq_data = np.fromfile(f\"{channel_path}/iqdata/example_{k + 1}.dat\", np.csingle)\n",
    "        iq_data = np.reshape(iq_data, (-1, data_obs_int))  # Turn the IQ data into chunks of (chunk size) x (data_obs_int)\n",
    "        for j in range(iq_data.shape[0]):\n",
    "            iq_array_norm = iq_data[j][:] / np.max(np.abs(iq_data[j][:]))  # Normalize the observation\n",
    "            iq_array = np.vstack((iq_array_norm.real, iq_array_norm.imag))  # Separate into 2 subarrays - 1 with only real (in-phase), the other only imaginary (quadrature)\n",
    "\n",
    "            # Pad the iq array with zeros to meet the observation length requirement\n",
    "            # This is needed because the CNN models have a fixed input size\n",
    "            iq_array = np.pad(iq_array, ((0, 0), (0, MODELS_OBS_INT - iq_array[0].size)), mode='constant', constant_values=0)\n",
    "\n",
    "            training_data[last_index, 0, :, :] = iq_array\n",
    "            last_index += 1\n",
    "    return torch.utils.data.DataLoader([training_data[i] for i in range(num_train_examples)], batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed5cd54a-d42c-4c3b-a6a0-9e03159c31b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_labels(channel_path, batch_size, num_batches, num_train_examples, data_obs_int):\n",
    "    training_labels = torch.stack([torch.nn.functional.one_hot(torch.tensor(pd.read_csv(os.path.join(channel_path, f'labeldata/example_{i+1}.csv')).iloc[:,0])) for i in range(num_batches)])\n",
    "    # print (training_labels)\n",
    "    return training_labels\n",
    "    # return torch.utils.data.DataLoader(training_labels, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da4badb0-9f05-42b2-a64c-8e73a6b07e04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([21, 5000, 8])\n",
      "number of missing labels: 0\n"
     ]
    }
   ],
   "source": [
    "num_batches = 21\n",
    "CHUNK_SIZE = 5000\n",
    "num_train_examples = num_batches * CHUNK_SIZE\n",
    "OBS_INT = 2048\n",
    "\n",
    "labels = load_labels(\"../data/dataset/team1/train\", 21, num_batches, num_train_examples, 2048)\n",
    "print (type(labels))\n",
    "\n",
    "print(labels.shape)\n",
    "count_all_zeros = 0\n",
    "labels = labels.numpy()\n",
    "for i in range(len(labels)):\n",
    "    if np.sum(labels[i]) == 0:\n",
    "        count_all_zeros += 1\n",
    "\n",
    "print(\"number of missing labels:\", count_all_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32465ae0-9a1b-435b-91e6-78d193cf5564",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data\n"
     ]
    }
   ],
   "source": [
    "#set directory paths\n",
    "#change to correct for testing data\n",
    "train_dir1 = os.path.join('../data/dataset', 'team1', 'train')\n",
    "train_iq_files = os.path.join(train_dir1, 'iqdata', 'example_*.dat')\n",
    "train_dir2 = os.path.join('../data/dataset', 'team2', 'train')\n",
    "train_iq_files = os.path.join(train_dir2, 'iqdata', 'example_*.dat')\n",
    "train_dir3 = os.path.join('../data/dataset', 'team3', 'train')\n",
    "train_iq_files = os.path.join(train_dir3, 'iqdata', 'example_*.dat')\n",
    "train_dir4 = os.path.join('../data/dataset', 'team4', 'train')\n",
    "train_iq_files = os.path.join(train_dir4, 'iqdata', 'example_*.dat')\n",
    "\n",
    "num_batches = 21\n",
    "CHUNK_SIZE = 5000\n",
    "num_train_examples = num_batches * CHUNK_SIZE\n",
    "OBS_INT = 2048\n",
    "team1_train_dataloader = load_data(train_dir1, 1, num_batches, num_train_examples, 2048)\n",
    "team2_train_dataloader = load_data(train_dir2, 1, num_batches, num_train_examples, 1024)\n",
    "team3_train_dataloader = load_data(train_dir3, 1, num_batches, num_train_examples, 512)\n",
    "team4_train_dataloader = load_data(train_dir4, 1, num_batches, num_train_examples, 256)\n",
    "print (\"loaded data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0198e8b1-f91e-4185-84c1-8168cd3d8a25",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "913dc232-a61e-49b6-8ba5-6a97955e90c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b1b40ba-8809-4707-be79-096b646f60fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=100, out_features=65, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105000it [02:02, 856.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features size:  torch.Size([105000, 65])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# team 1 features\n",
    "features = {}\n",
    "\n",
    "selected_layer = getattr(team1_model, \"fc3\")  #sometimes its just model or model.module\n",
    "input_features = selected_layer.in_features\n",
    "selected_layer.register_forward_hook(get_features('feats'))\n",
    "print(selected_layer)\n",
    "\n",
    "preds_list = []\n",
    "feats_list1 = []\n",
    "\n",
    "\n",
    "# Feed the IQ data into the model\n",
    "for idx, inputs in tqdm(enumerate(team1_train_dataloader)):\n",
    "    with torch.inference_mode():\n",
    "        preds = team1_model(inputs.to(device))\n",
    "    feats_list1.append(features['feats'].cpu().numpy())\n",
    "\n",
    "feats_list1 = np.concatenate(feats_list1)\n",
    "\n",
    "features1 = np.array(feats_list1)\n",
    "features1 = torch.tensor(features1)\n",
    "features1 = features1.reshape(-1, features1.shape[-1])\n",
    "print(\"features size: \", features1.size())\n",
    "print (type(features1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d21bc7b4-b28a-4125-9098-920c1df9ccdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LazyLinear(in_features=0, out_features=512, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105000it [03:11, 548.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features size:  torch.Size([105000, 512])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# team 2 features\n",
    "features = {}\n",
    "\n",
    "selected_layer = getattr(team2_model, \"fc1\")  #sometimes its just model or model.module\n",
    "input_features = selected_layer.in_features\n",
    "selected_layer.register_forward_hook(get_features('feats'))\n",
    "print(selected_layer)\n",
    "\n",
    "preds_list = []\n",
    "feats_list2 = []\n",
    "\n",
    "# Feed the IQ data into the model\n",
    "for idx, inputs in tqdm(enumerate(team2_train_dataloader)):\n",
    "    with torch.inference_mode():\n",
    "        preds = team2_model(inputs.to(device))\n",
    "    feats_list2.append(features['feats'].cpu().numpy())\n",
    "\n",
    "feats_list2 = np.concatenate(feats_list2)\n",
    "\n",
    "features2 = np.array(feats_list2)\n",
    "features2 = torch.tensor(features2)\n",
    "features2 = features2.reshape(-1, features2.shape[-1])\n",
    "print(\"features size: \", features2.size())\n",
    "print (type(features2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26923522-e0c2-4c23-93f3-66bd6585b79a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=128, out_features=64, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105000it [24:20, 71.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features size:  torch.Size([105000, 64])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# team 3 features\n",
    "features = {}\n",
    "\n",
    "selected_layer = getattr(team3_model, \"fc3\")  #sometimes its just model or model.module\n",
    "input_features = selected_layer.in_features\n",
    "selected_layer.register_forward_hook(get_features('feats'))\n",
    "print(selected_layer)\n",
    "\n",
    "preds_list = []\n",
    "feats_list3 = []\n",
    "\n",
    "# Feed the IQ data into the model\n",
    "for idx, inputs in tqdm(enumerate(team3_train_dataloader)):\n",
    "    with torch.inference_mode():\n",
    "        preds = team3_model(inputs.to(device))\n",
    "    feats_list3.append(features['feats'].cpu().numpy())\n",
    "\n",
    "feats_list3 = np.concatenate(feats_list3)\n",
    "\n",
    "features3 = np.array(feats_list3)\n",
    "features3 = torch.tensor(features3)\n",
    "features3 = features3.reshape(-1, features3.shape[-1])\n",
    "print(\"features size: \", features3.size())\n",
    "print (type(features3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34cfcc07-4244-4733-9b57-0a9c37344540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=512, out_features=256, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105000it [24:33, 71.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features size:  torch.Size([105000, 256])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# team 4 features\n",
    "features = {}\n",
    "\n",
    "selected_layer = getattr(team4_model, \"fc2\")  #sometimes its just model or model.module\n",
    "input_features = selected_layer.in_features\n",
    "selected_layer.register_forward_hook(get_features('feats'))\n",
    "print(selected_layer)\n",
    "\n",
    "preds_list = []\n",
    "feats_list4 = []\n",
    "\n",
    "# Feed the IQ data into the model\n",
    "for idx, inputs in tqdm(enumerate(team4_train_dataloader)):\n",
    "    with torch.inference_mode():\n",
    "        preds = team4_model(inputs.to(device))\n",
    "    feats_list4.append(features['feats'].cpu().numpy())\n",
    "\n",
    "feats_list4 = np.concatenate(feats_list4)\n",
    "\n",
    "features4 = np.array(feats_list4)\n",
    "features4 = torch.tensor(features4)\n",
    "features4 = features4.reshape(-1, features4.shape[-1])\n",
    "print(\"features size: \", features4.size())\n",
    "print (type(features4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57113b17-e73a-4d86-9ab8-aaf723706df5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined_tensor size: torch.Size([105000, 897])\n"
     ]
    }
   ],
   "source": [
    "combined_tensor = torch.cat((features1, features2, features3, features4), dim=1)\n",
    "print(f\"Combined_tensor size: {combined_tensor.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d829b85-20d7-4e58-b5c2-0503c9c9ff03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape:  (105000, 8)\n"
     ]
    }
   ],
   "source": [
    "labels_list = []\n",
    "\n",
    "testloader = load_labels(\"../data/dataset/team1/train\", 1, num_batches, num_train_examples, 2048)\n",
    "x = 0\n",
    "for batch in testloader:\n",
    "    #print(batch)\n",
    "    if torch.sum(batch) == 0:\n",
    "        print(f'Found all zeros at index {x}')\n",
    "    labels = batch  \n",
    "    labels_list.append(labels)\n",
    "    x += 1\n",
    "\n",
    "all_labels = torch.cat(labels_list, dim=0)\n",
    "labels= all_labels.numpy()\n",
    "print(\"labels shape: \", labels.shape)\n",
    "# print (labels.shape)\n",
    "#torch.save(labels, \"new_updated_labels_second_to_last.pt\")\n",
    "# print (combined_tensor.shape)\n",
    "# print(labels.reshape(105000, 8)[75000:80000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6196c11f-6ca5-404b-bae4-3180182a35f1",
   "metadata": {},
   "source": [
    "## Training model/saving extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebafc34e-bfad-430a-a4c0-0ee5ce069c95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the extracted features and labels for fusion in other scripts\n",
    "fusion_data_folder = '../data/fusion_data'\n",
    "\n",
    "# Save features for the individual models\n",
    "with open(os.path.join(fusion_data_folder, 'team1_features_second_to_last.npy'), 'wb') as f:\n",
    "    np.save(f, features1.numpy())\n",
    "with open(os.path.join(fusion_data_folder, 'team2_features_second_to_last.npy'), 'wb') as f:\n",
    "    np.save(f, features2.numpy())\n",
    "with open(os.path.join(fusion_data_folder, 'team3_features_second_to_last.npy'), 'wb') as f:\n",
    "    np.save(f, features3.numpy())\n",
    "with open(os.path.join(fusion_data_folder, 'team4_features_second_to_last.npy'), 'wb') as f:\n",
    "    np.save(f, features4.numpy())\n",
    "\n",
    "# Save combined features\n",
    "with open(os.path.join(fusion_data_folder, 'combined_features_allsecond_to_last.npy'), 'wb') as f:\n",
    "    np.save(f, combined_tensor.numpy())\n",
    "\n",
    "# Save labels\n",
    "with open(os.path.join(fusion_data_folder, 'labels.npy'), 'wb') as f:\n",
    "    np.save(f, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daf535f7-a22a-46f5-8a22-a0e98a649e3f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "[[-9.5405815e+01 -1.0237858e+02 -4.9376961e+01 ... -7.5925851e+00\n",
      "  -8.4549570e+00 -6.4325814e+00]\n",
      " [-3.4990044e+01 -8.1022453e+01 -1.6680246e+01 ... -7.8388405e-01\n",
      "  -2.3498110e+01 -2.1892767e+01]\n",
      " [-2.8673544e+02  1.2923242e+02  2.1418201e+03 ... -9.5032568e+00\n",
      "  -1.3903454e+01 -1.2622296e+01]\n",
      " ...\n",
      " [-6.0012109e+02 -5.6118690e+01  4.5613013e+03 ... -9.0246153e+00\n",
      "  -1.2385365e+01 -1.0883750e+01]\n",
      " [-1.5780228e+01 -2.2764688e+01 -1.3417933e+01 ... -1.6095691e+00\n",
      "  -8.7466068e+00 -6.1196389e+00]\n",
      " [-3.7305004e+01 -7.1418030e+01 -6.3897972e+01 ... -1.2154825e+01\n",
      "  -9.3149185e+00 -1.6690149e+01]]\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[0]\tvalidation_0-logloss:0.20531\n",
      "[1]\tvalidation_0-logloss:0.14276\n",
      "[2]\tvalidation_0-logloss:0.10217\n",
      "[3]\tvalidation_0-logloss:0.07427\n",
      "[4]\tvalidation_0-logloss:0.05457\n",
      "[5]\tvalidation_0-logloss:0.04041\n",
      "[6]\tvalidation_0-logloss:0.03013\n",
      "[7]\tvalidation_0-logloss:0.02265\n",
      "[8]\tvalidation_0-logloss:0.01716\n",
      "[9]\tvalidation_0-logloss:0.01312\n",
      "[10]\tvalidation_0-logloss:0.01016\n",
      "[11]\tvalidation_0-logloss:0.00797\n",
      "[12]\tvalidation_0-logloss:0.00635\n",
      "[13]\tvalidation_0-logloss:0.00516\n",
      "[14]\tvalidation_0-logloss:0.00426\n",
      "[15]\tvalidation_0-logloss:0.00361\n",
      "[16]\tvalidation_0-logloss:0.00311\n",
      "[17]\tvalidation_0-logloss:0.00277\n",
      "[18]\tvalidation_0-logloss:0.00248\n",
      "[19]\tvalidation_0-logloss:0.00226\n",
      "[20]\tvalidation_0-logloss:0.00210\n",
      "[21]\tvalidation_0-logloss:0.00198\n",
      "[22]\tvalidation_0-logloss:0.00188\n",
      "[23]\tvalidation_0-logloss:0.00181\n",
      "[24]\tvalidation_0-logloss:0.00176\n",
      "[25]\tvalidation_0-logloss:0.00171\n",
      "[26]\tvalidation_0-logloss:0.00168\n",
      "[27]\tvalidation_0-logloss:0.00164\n",
      "[28]\tvalidation_0-logloss:0.00163\n",
      "[29]\tvalidation_0-logloss:0.00162\n",
      "[30]\tvalidation_0-logloss:0.00161\n",
      "[31]\tvalidation_0-logloss:0.00161\n",
      "[32]\tvalidation_0-logloss:0.00159\n",
      "[33]\tvalidation_0-logloss:0.00158\n",
      "[34]\tvalidation_0-logloss:0.00158\n",
      "[35]\tvalidation_0-logloss:0.00159\n",
      "[36]\tvalidation_0-logloss:0.00159\n",
      "[37]\tvalidation_0-logloss:0.00158\n",
      "[38]\tvalidation_0-logloss:0.00158\n",
      "[39]\tvalidation_0-logloss:0.00158\n",
      "[40]\tvalidation_0-logloss:0.00158\n",
      "[41]\tvalidation_0-logloss:0.00159\n",
      "[42]\tvalidation_0-logloss:0.00158\n",
      "[43]\tvalidation_0-logloss:0.00159\n",
      "[44]\tvalidation_0-logloss:0.00159\n",
      "[45]\tvalidation_0-logloss:0.00158\n",
      "[46]\tvalidation_0-logloss:0.00158\n",
      "[47]\tvalidation_0-logloss:0.00158\n",
      "[48]\tvalidation_0-logloss:0.00159\n",
      "[49]\tvalidation_0-logloss:0.00159\n",
      "[50]\tvalidation_0-logloss:0.00159\n",
      "[51]\tvalidation_0-logloss:0.00159\n",
      "[52]\tvalidation_0-logloss:0.00159\n",
      "[53]\tvalidation_0-logloss:0.00159\n",
      "[54]\tvalidation_0-logloss:0.00160\n",
      "[55]\tvalidation_0-logloss:0.00160\n",
      "[56]\tvalidation_0-logloss:0.00160\n",
      "[57]\tvalidation_0-logloss:0.00160\n",
      "[58]\tvalidation_0-logloss:0.00161\n",
      "[59]\tvalidation_0-logloss:0.00161\n",
      "[60]\tvalidation_0-logloss:0.00161\n",
      "[61]\tvalidation_0-logloss:0.00162\n",
      "[62]\tvalidation_0-logloss:0.00162\n",
      "[63]\tvalidation_0-logloss:0.00162\n",
      "[64]\tvalidation_0-logloss:0.00163\n",
      "[65]\tvalidation_0-logloss:0.00163\n",
      "[66]\tvalidation_0-logloss:0.00163\n",
      "[67]\tvalidation_0-logloss:0.00162\n",
      "[68]\tvalidation_0-logloss:0.00163\n",
      "[69]\tvalidation_0-logloss:0.00163\n",
      "[70]\tvalidation_0-logloss:0.00164\n",
      "[71]\tvalidation_0-logloss:0.00164\n",
      "[72]\tvalidation_0-logloss:0.00164\n",
      "[73]\tvalidation_0-logloss:0.00164\n",
      "[74]\tvalidation_0-logloss:0.00164\n",
      "[75]\tvalidation_0-logloss:0.00164\n",
      "[76]\tvalidation_0-logloss:0.00165\n",
      "[77]\tvalidation_0-logloss:0.00164\n",
      "[78]\tvalidation_0-logloss:0.00165\n",
      "[79]\tvalidation_0-logloss:0.00165\n",
      "[80]\tvalidation_0-logloss:0.00165\n",
      "[81]\tvalidation_0-logloss:0.00166\n",
      "[82]\tvalidation_0-logloss:0.00166\n",
      "[83]\tvalidation_0-logloss:0.00166\n",
      "[84]\tvalidation_0-logloss:0.00166\n",
      "[85]\tvalidation_0-logloss:0.00166\n",
      "[86]\tvalidation_0-logloss:0.00166\n",
      "[87]\tvalidation_0-logloss:0.00166\n",
      "[88]\tvalidation_0-logloss:0.00166\n",
      "[89]\tvalidation_0-logloss:0.00166\n",
      "[90]\tvalidation_0-logloss:0.00167\n",
      "[91]\tvalidation_0-logloss:0.00166\n",
      "[92]\tvalidation_0-logloss:0.00167\n",
      "[93]\tvalidation_0-logloss:0.00167\n",
      "[94]\tvalidation_0-logloss:0.00166\n",
      "[95]\tvalidation_0-logloss:0.00166\n",
      "[96]\tvalidation_0-logloss:0.00167\n",
      "[97]\tvalidation_0-logloss:0.00167\n",
      "[98]\tvalidation_0-logloss:0.00167\n",
      "[99]\tvalidation_0-logloss:0.00167\n",
      "[2 2 2 ... 7 7 2]\n",
      "Accuracy: 0.9980476190476191\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(combined_tensor.numpy(), labels.reshape(105000, 8), test_size=0.2, random_state=42)\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  \n",
    "    'num_class': num_classes,      \n",
    "    'eval_metric': 'merror',       \n",
    "    'max_depth': 6,                \n",
    "    'min_child_weight': 1,         \n",
    "    'subsample': 0.8,              \n",
    "    'colsample_bytree': 0.8,       \n",
    "    'learning_rate': 0.1,          \n",
    "    'n_estimators': 100            \n",
    "}\n",
    "\n",
    "num_rounds = 15  \n",
    "print (\"split\")\n",
    "\n",
    "#print(len(X_train))\n",
    "#print(len(X_test))\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "\n",
    "model_fused = xgb.XGBClassifier(tree_method=\"hist\")\n",
    "model_fused.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
    "\n",
    "preds = model_fused.predict(X_test).argmax(1)\n",
    "#preds = model_fused.predict(X_test)\n",
    "print(preds)\n",
    "acc = (preds == y_test.argmax(1)).sum() / preds.shape[0]\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4babc77-b7a3-4006-bfa4-874f240a6e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_fused.save_model('../data/summer_models/baseline_fused_2tl.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4cdd5-9026-4a00-8fe4-2c3ad34b896d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
