{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b91f3729-ead2-4e8f-a1e1-1e6904d71155",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b7ad1be-c26d-410f-851f-ba3a5fe8028b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: False\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost\n",
    "#!pip install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --user\n",
    "#!pip install torchinfo\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "#os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "import torch\n",
    "#import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "#from stable_baselines3 import PPO\n",
    "#from torchinfo import summary\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print('Cuda available:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a840ca9c-8aef-4625-ba23-2009097b9708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Team1Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(2, 16))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=(1, 8))\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(1, 8))\n",
    "        #self.fc1 = nn.Linear(in_features=15360, out_features=1200)  # Fully Connected Layer\n",
    "        self.fc1 = nn.LazyLinear(out_features=1200)\n",
    "        self.fc2 = nn.Linear(in_features=1200, out_features=100)\n",
    "        self.fc3 = nn.Linear(in_features=100, out_features=65)\n",
    "        self.fc4 = nn.Linear(in_features=65, out_features=self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # print(f'after conv1: {x.shape}')\n",
    "        x = self.pool(x)\n",
    "        # print(f'after pool: {x.shape}')\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # print(f'after conv2: {x.shape}')\n",
    "        x = self.pool(x)\n",
    "        # print(f'after pool: {x.shape}')\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # print(f'after conv3: {x.shape}')\n",
    "        x = self.pool(x)\n",
    "        # print(f'after pool: {x.shape}')\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        # print(f'after reshaping: {x.shape}')\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # print(f'fc1: {x.shape}')\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # print(f'fc2: {x.shape}')\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # print(f'fc3: {x.shape}')\n",
    "        #x = F.relu(self.fc4(x))\n",
    "        x = self.fc4(x)\n",
    "        # print(f'fc3: {x.shape}')\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aae8b994-65d4-4ced-9558-cdad1ee003cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Team2Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(2, 128, 8, dtype=torch.float32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Conv1d(128, 256, 8, dtype=torch.float32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Conv1d(256, 512, 8, dtype=torch.float32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Conv1d(512, 1024, 8, dtype=torch.float32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.BatchNorm1d(1024),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.LazyLinear(512, dtype=torch.float32)\n",
    "        self.fc2 = nn.Linear(512, num_classes, dtype=torch.float32)\n",
    "        # self.fc = nn.Sequential(\n",
    "        #     nn.LazyLinear(512, dtype=torch.float32),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(512, num_classes, dtype=torch.float32),\n",
    "        #     nn.ReLU(),\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        x = x.flatten(1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        #return F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143e0848-aa7a-4678-94a3-01917b5e45ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# From headley_modrec.py\n",
    "class Team3Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 16, (2, 16))\n",
    "        self.conv2 = nn.Conv2d(16, 8, (1, 8))\n",
    "        self.conv3 = nn.Conv2d(8, 4, (1, 4))\n",
    "        #self.fc1 = nn.Linear(3996, 512)\n",
    "        self.fc1 = nn.LazyLinear(out_features=512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, self.num_classes)\n",
    "\n",
    "        self.activation = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        x = F.tanh(self.conv2(x))\n",
    "        x = F.tanh(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "046f1a81-f39d-4d47-9122-0ffe3ee4dc6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Team4Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.re1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.re2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.re3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.re4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        #self.fc1 = nn.Linear(128 * 256,512)  # I dont exactly know why it is 128x256, but I had to do some debugging and hardcode the required value\n",
    "        self.fc1 = nn.LazyLinear(out_features=512)\n",
    "\n",
    "        self.re5 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.re6 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.re1(self.conv1(x)))\n",
    "        x = self.pool2(self.re2(self.conv2(x)))\n",
    "        x = self.pool3(self.re3(self.conv3(x)))\n",
    "        x = self.pool4(self.re4(self.conv4(x)))\n",
    "        x = self.flat(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.re5(self.fc1(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.re6(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "019c85ce-9876-40eb-9069-b0f091f83b56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded team1\n",
      "loaded team2\n",
      "loaded team3\n",
      "loaded team4\n",
      "# trainable params, team 1: 38295641\n",
      "# trainable params, team 2: 8138888\n",
      "# trainable params, team 3: 4219748\n",
      "# trainable params, team 4: 34076168\n"
     ]
    }
   ],
   "source": [
    "sig_types = [['2-ASK', ['ask', 2], 0],\n",
    "             ['4-ASK', ['ask', 4], 1],\n",
    "             ['8-ASK', ['ask', 8], 2],\n",
    "             ['BPSK', ['psk', 2], 3],\n",
    "             ['QPSK', ['psk', 4], 4],\n",
    "             ['16-QAM', ['qam', 16], 5],\n",
    "             ['Tone', ['constant'], 6],\n",
    "             ['P-FMCW', ['p_fmcw'], 7]]\n",
    "num_classes = len(sig_types)\n",
    "sig_names = [i[0] for i in sig_types]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('Using device', device)\n",
    "\n",
    "team1_model = Team1Model(num_classes)\n",
    "team1_model.load_state_dict(torch.load('../models/team1_model.pt', map_location=torch.device('cpu')))\n",
    "team1_model.eval()\n",
    "team1_model.to(device)\n",
    "print (\"loaded team1\")\n",
    "\n",
    "team2_model = Team2Model(num_classes)\n",
    "team2_model.load_state_dict(torch.load('../models/team2_model.pt', map_location=torch.device('cpu')))\n",
    "team2_model.eval()\n",
    "team2_model.to(device)\n",
    "print (\"loaded team2\")\n",
    "team3_model = Team3Model(num_classes)\n",
    "team3_model.load_state_dict(torch.load('../models/team3_model.pt', map_location=torch.device('cpu')))\n",
    "team3_model.eval()\n",
    "team3_model.to(device)\n",
    "print (\"loaded team3\")\n",
    "team4_model = Team4Model(num_classes)\n",
    "team4_model.load_state_dict(torch.load('../models/team4_model.pt', map_location=torch.device('cpu')))\n",
    "team4_model.eval()\n",
    "team4_model.to(device)\n",
    "print (\"loaded team4\")\n",
    "\n",
    "# # Load regular fused model\n",
    "# reg_fused_model = xgb.XGBClassifier(tree_method=\"hist\")\n",
    "# reg_fused_model.load_model('../data/summer_models/baseline_fused_2tl.json')\n",
    "# print('loaded baseline fused model')\n",
    "\n",
    "# # Load RL fused model\n",
    "# rl_fused_model = xgb.XGBClassifier(tree_method=\"hist\", early_stopping_rounds=2, n_estimators=5)\n",
    "# rl_fused_model.load_model('../data/summer_models/rl_fused_2tl.json')\n",
    "# with open('../data/summer_models/rl_feature_idxes_2tl.pkl', 'rb') as f:\n",
    "#     rl_feature_idxes = pickle.load(f)\n",
    "# print('loaded RL fused model')\n",
    "\n",
    "# # Load RFE fused model\n",
    "# rfe_fused_model = xgb.XGBClassifier(tree_method=\"hist\", early_stopping_rounds=2)\n",
    "# rfe_fused_model.load_model('../data/summer_models/rfe_fused_2tl.json')\n",
    "# with open('../data/summer_models/rfe_feature_idxes_2tl.pkl', 'rb') as f:\n",
    "#     rfe_feature_idxes = pickle.load(f)\n",
    "# print('loaded RFE fused model')\n",
    "\n",
    "# Get the number of trainable parameters in each of the teams' models\n",
    "team1_params = sum(p.numel() for p in team1_model.parameters() if p.requires_grad)\n",
    "team2_params = sum(p.numel() for p in team2_model.parameters() if p.requires_grad)\n",
    "team3_params = sum(p.numel() for p in team3_model.parameters() if p.requires_grad)\n",
    "team4_params = sum(p.numel() for p in team4_model.parameters() if p.requires_grad)\n",
    "print('# trainable params, team 1:', team1_params)\n",
    "print('# trainable params, team 2:', team2_params)\n",
    "print('# trainable params, team 3:', team3_params)\n",
    "print('# trainable params, team 4:', team4_params)\n",
    "\n",
    "#summary(team1_model, input_size=(1, 1, 2, 2048))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6118e623-d453-44c0-a42a-91315b38a8ef",
   "metadata": {},
   "source": [
    "## Helper functions/loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fc2fbe3-9fda-47f0-808e-33a970ff3d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODELS_OBS_INT = 2048\n",
    "def load_data(channel_path, batch_size, num_batches, num_train_examples, data_obs_int):\n",
    "    training_data = np.zeros((num_train_examples, 1, 2, MODELS_OBS_INT), dtype=np.float32)\n",
    "\n",
    "    last_index = 0\n",
    "    for k in range(num_batches):\n",
    "        # This is used if we have a labeldata folder that stores class labels\n",
    "        label_df = pd.read_csv(f\"{channel_path}/labeldata/example_{k + 1}.csv\")\n",
    "\n",
    "        num_nans = 0\n",
    "        iq_file_name = f\"{channel_path}/iqdata/example_{k + 1}.dat\"\n",
    "        iq_data = np.fromfile(iq_file_name, np.csingle)\n",
    "        iq_data = np.reshape(iq_data, (-1, data_obs_int))  # Turn the IQ data into chunks of (chunk size) x (data_obs_int)\n",
    "        for j in range(iq_data.shape[0]):\n",
    "            # Check if the current row contains NaN values\n",
    "            if np.isnan(np.sum(iq_data[j][:])):    \n",
    "                num_nans += 1\n",
    "            else:\n",
    "                iq_array_norm = iq_data[j][:] / np.max(np.abs(iq_data[j][:]))  # Normalize the observation\n",
    "                iq_array = np.vstack((iq_array_norm.real, iq_array_norm.imag))  # Separate into 2 subarrays - 1 with only real (in-phase), the other only imaginary (quadrature)\n",
    "\n",
    "                # Pad the iq array with zeros to meet the observation length requirement\n",
    "                # This is needed because the CNN models have a fixed input size\n",
    "                iq_array = np.pad(iq_array, ((0, 0), (0, MODELS_OBS_INT - iq_array[0].size)), mode='constant', constant_values=0)\n",
    "\n",
    "                training_data[last_index, 0, :, :] = iq_array\n",
    "            last_index += 1\n",
    "        \n",
    "        if num_nans > 0:\n",
    "            print(f'Found {num_nans} rows containing NaNs in {iq_file_name}')\n",
    "    return torch.utils.data.DataLoader([training_data[i] for i in range(num_train_examples)], batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c4fb22f-ec51-405b-a50e-66b9252c0148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_labels(channel_path, batch_size, num_batches, num_train_examples, data_obs_int):\n",
    "    # for i in range(num_batches):\n",
    "    #     data = pd.read_csv(os.path.join(channel_path, f'labeldata/example_{i+1}.csv')).iloc[:,0]\n",
    "    #     tensor_data = torch.tensor(data)\n",
    "    #     print(tensor_data.shape)\n",
    "    #     print(torch.nn.functional.one_hot(tensor_data).shape)\n",
    "    #     print(torch.stack([torch.nn.functional.one_hot(tensor_data)]).shape)\n",
    "    training_labels = torch.stack([torch.nn.functional.one_hot(torch.tensor(pd.read_csv(os.path.join(channel_path, f'labeldata/example_{i+1}.csv')).iloc[:,0])) for i in range(num_batches)])\n",
    "    return training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8af66c45-bfa4-4cf0-9ebc-75600649743c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [10, 8] at entry 0 and [10, 7] at entry 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m TEAM1_OBS_INT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2048\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# TEAM2_OBS_INT = 1024\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# TEAM3_OBS_INT = 512\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# TEAM4_OBS_INT = 256\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_dir1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_validation_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODELS_OBS_INT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     23\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mreshape((labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m     24\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(labels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[40], line 8\u001b[0m, in \u001b[0;36mload_labels\u001b[0;34m(channel_path, batch_size, num_batches, num_train_examples, data_obs_int)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_labels\u001b[39m(channel_path, batch_size, num_batches, num_train_examples, data_obs_int):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# for i in range(num_batches):\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#     data = pd.read_csv(os.path.join(channel_path, f'labeldata/example_{i+1}.csv')).iloc[:,0]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#     print(torch.nn.functional.one_hot(tensor_data).shape)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#     print(torch.stack([torch.nn.functional.one_hot(tensor_data)]).shape)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     training_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabeldata/example_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m training_labels\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [10, 8] at entry 0 and [10, 7] at entry 9"
     ]
    }
   ],
   "source": [
    "#set directory paths\n",
    "#change to correct for testing data\n",
    "validation_dir1 = os.path.join('../data', 'validation', '1',)\n",
    "validation_iq_files = os.path.join(validation_dir1, 'iqdata', 'example_*.dat')\n",
    "joined_list = glob.glob(validation_iq_files)\n",
    "num_batches = len(joined_list)\n",
    "validation_dir2 = os.path.join('../data', 'validation', '2')\n",
    "validation_iq_files = os.path.join(validation_dir2, 'iqdata', 'example_*.dat')\n",
    "validation_dir3 = os.path.join('../data', 'validation', '3')\n",
    "validation_iq_files = os.path.join(validation_dir3, 'iqdata', 'example_*.dat')\n",
    "validation_dir4 = os.path.join('../data', 'validation', '4')\n",
    "validation_iq_files = os.path.join(validation_dir4, 'iqdata', 'example_*.dat')\n",
    "\n",
    "#num_batches = 6\n",
    "CHUNK_SIZE = 10\n",
    "num_validation_examples = num_batches * CHUNK_SIZE\n",
    "MODELS_OBS_INT = 2048\n",
    "TEAM1_OBS_INT = 2048\n",
    "# TEAM2_OBS_INT = 1024\n",
    "# TEAM3_OBS_INT = 512\n",
    "# TEAM4_OBS_INT = 256\n",
    "labels = load_labels(validation_dir1, 1, num_batches, num_validation_examples, MODELS_OBS_INT).numpy()\n",
    "labels = labels.reshape((labels.shape[0] * labels.shape[1], labels.shape[2]))\n",
    "labels = np.argmax(labels, axis=1)\n",
    "team1_validation_dataloader = load_data(validation_dir1, 1, num_batches, num_validation_examples, 2048)\n",
    "team2_validation_dataloader = load_data(validation_dir2, 1, num_batches, num_validation_examples, 1024)\n",
    "team3_validation_dataloader = load_data(validation_dir3, 1, num_batches, num_validation_examples, 512)\n",
    "team4_validation_dataloader = load_data(validation_dir4, 1, num_batches, num_validation_examples, 256)\n",
    "print (\"loaded data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff89a68-c09d-40ae-b91d-fdf858b47d8a",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6091ac9b-935b-4914-bd4e-f961ebaa1b53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac89d6-b3c8-44ed-becf-1caaadeba5e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# team 1 features\n",
    "features = {}\n",
    "\n",
    "selected_layer = getattr(team1_model, \"fc3\")  #sometimes its just model or model.module\n",
    "input_features = selected_layer.in_features\n",
    "selected_layer.register_forward_hook(get_features('feats'))\n",
    "\n",
    "preds_list = []\n",
    "feats_list1 = []\n",
    "\n",
    "\n",
    "# Feed the IQ data into the model\n",
    "for idx, inputs in tqdm(enumerate(team1_validation_dataloader)):\n",
    "    with torch.inference_mode():\n",
    "        preds = team1_model(inputs.to(device))\n",
    "    feats_list1.append(features['feats'].cpu().numpy())\n",
    "\n",
    "feats_list1 = np.concatenate(feats_list1)\n",
    "\n",
    "features1 = np.array(feats_list1)\n",
    "features1 = torch.tensor(features1)\n",
    "features1 = features1.reshape(-1, features1.shape[-1])\n",
    "print(\"features size: \", features1.size())\n",
    "print (type(features1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3a00b6-d136-424a-8d94-c4144ba6763c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# team 2 features\n",
    "features = {}\n",
    "\n",
    "selected_layer = getattr(team2_model, \"fc1\")  #sometimes its just model or model.module\n",
    "input_features = selected_layer.in_features\n",
    "selected_layer.register_forward_hook(get_features('feats'))\n",
    "\n",
    "preds_list = []\n",
    "feats_list2 = []\n",
    "\n",
    "# Feed the IQ data into the model\n",
    "for idx, inputs in tqdm(enumerate(team2_validation_dataloader)):\n",
    "    with torch.inference_mode():\n",
    "        preds = team2_model(inputs.to(device))\n",
    "    feats_list2.append(features['feats'].cpu().numpy())\n",
    "\n",
    "feats_list2 = np.concatenate(feats_list2)\n",
    "\n",
    "features2 = np.array(feats_list2)\n",
    "features2 = torch.tensor(features2)\n",
    "features2 = features2.reshape(-1, features2.shape[-1])\n",
    "print(\"features size: \", features2.size())\n",
    "print (type(features2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406af920-e4d5-4323-b518-040c8bbad0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# team 3 features\n",
    "features = {}\n",
    "\n",
    "selected_layer = getattr(team3_model, \"fc3\")  #sometimes its just model or model.module\n",
    "input_features = selected_layer.in_features\n",
    "selected_layer.register_forward_hook(get_features('feats'))\n",
    "\n",
    "preds_list = []\n",
    "feats_list3 = []\n",
    "\n",
    "# Feed the IQ data into the model\n",
    "for idx, inputs in tqdm(enumerate(team3_validation_dataloader)):\n",
    "    with torch.inference_mode():\n",
    "        preds = team3_model(inputs.to(device))\n",
    "    feats_list3.append(features['feats'].cpu().numpy())\n",
    "\n",
    "feats_list3 = np.concatenate(feats_list3)\n",
    "\n",
    "features3 = np.array(feats_list3)\n",
    "features3 = torch.tensor(features3)\n",
    "features3 = features3.reshape(-1, features3.shape[-1])\n",
    "print(\"features size: \", features3.size())\n",
    "print (type(features3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ea6a8-fa8a-400a-bd3e-2dad350e64d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# team 4 features\n",
    "features = {}\n",
    "\n",
    "selected_layer = getattr(team4_model, \"fc2\")  #sometimes its just model or model.module\n",
    "input_features = selected_layer.in_features\n",
    "selected_layer.register_forward_hook(get_features('feats'))\n",
    "\n",
    "preds_list = []\n",
    "feats_list4 = []\n",
    "\n",
    "# Feed the IQ data into the model\n",
    "for idx, inputs in tqdm(enumerate(team4_validation_dataloader)):\n",
    "    with torch.inference_mode():\n",
    "        preds = team4_model(inputs.to(device))\n",
    "    feats_list4.append(features['feats'].cpu().numpy())\n",
    "\n",
    "feats_list4 = np.concatenate(feats_list4)\n",
    "\n",
    "features4 = np.array(feats_list4)\n",
    "features4 = torch.tensor(features4)\n",
    "features4 = features4.reshape(-1, features4.shape[-1])\n",
    "print(\"features size: \", features4.size())\n",
    "print (type(features4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5204f6a-ecaf-4037-93f3-27482705c3d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_tensor = torch.cat((features1, features2, features3, features4), dim=1)\n",
    "print(f\"Combined_tensor size: {combined_tensor.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b723b74-7544-4b9d-9411-138b3df6f77a",
   "metadata": {},
   "source": [
    "## Get accuracy and confusion matrix for regular fused model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e07cfb-e0dc-4650-8e5b-52e7eaeac11c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = np.argmax(reg_fused_model.predict(combined_tensor), axis=1)\n",
    "\n",
    "num_correct = np.sum(preds == labels)\n",
    "accuracy = num_correct / len(preds)\n",
    "print('Regular fused model validation accuracy:', accuracy)\n",
    "\n",
    "conf_mat = np.zeros((num_classes, num_classes))\n",
    "\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    feats = combined_tensor\n",
    "    outputs = reg_fused_model.predict(feats)\n",
    "    outputs = np.argmax(outputs, axis=1)\n",
    "            \n",
    "    for i in range(outputs.shape[0]):\n",
    "        conf_mat[labels[i], outputs[i]] += 1\n",
    "\n",
    "# Make each row sum to 1\n",
    "for i in range(conf_mat.shape[0]):\n",
    "    conf_mat[i] = conf_mat[i] / np.sum(conf_mat[i])\n",
    "\n",
    "figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, xticklabels=sig_names, yticklabels=sig_names, fmt='.2f')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Baseline Fused Model Confusion Matrix')\n",
    "plt.savefig('../data/fusion_plots/confusion_matrices/baseline_confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ac0fe-1d93-4b75-9a63-9624122ed143",
   "metadata": {},
   "source": [
    "## Get accuracy and confusion matrix for RL fused model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252685f-58af-469f-ab16-cef52867c765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = np.argmax(rl_fused_model.predict(combined_tensor[:, rl_feature_idxes]), axis=1)\n",
    "\n",
    "num_correct = np.sum(preds == labels)\n",
    "accuracy = num_correct / len(preds)\n",
    "print('RL fused model validation accuracy:', accuracy)\n",
    "\n",
    "conf_mat = np.zeros((num_classes, num_classes))\n",
    "\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    feats = combined_tensor\n",
    "    outputs = rl_fused_model.predict(feats[:, rl_feature_idxes])\n",
    "    outputs = np.argmax(outputs, axis=1)\n",
    "            \n",
    "    for i in range(outputs.shape[0]):\n",
    "        conf_mat[labels[i], outputs[i]] += 1\n",
    "\n",
    "# Make each row sum to 1\n",
    "for i in range(conf_mat.shape[0]):\n",
    "    conf_mat[i] = conf_mat[i] / np.sum(conf_mat[i])\n",
    "\n",
    "figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, xticklabels=sig_names, yticklabels=sig_names, fmt='.2f')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('RL Fused Model Confusion Matrix')\n",
    "plt.savefig('../data/fusion_plots/confusion_matrices/rl_confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccd7590-24e6-4610-a361-e31d685248f1",
   "metadata": {},
   "source": [
    "## Get accuracy and confusion matrix for RFE fused model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c56445-cfd2-4e48-97bc-0860291d5adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = np.argmax(rfe_fused_model.predict(combined_tensor[:, rfe_feature_idxes]), axis=1)\n",
    "\n",
    "num_correct = np.sum(preds == labels)\n",
    "accuracy = num_correct / len(preds)\n",
    "print('RFE fused model validation accuracy:', accuracy)\n",
    "\n",
    "conf_mat = np.zeros((num_classes, num_classes))\n",
    "\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    feats = combined_tensor\n",
    "    outputs = rfe_fused_model.predict(feats[:, rfe_feature_idxes])\n",
    "    outputs = np.argmax(outputs, axis=1)\n",
    "            \n",
    "    for i in range(outputs.shape[0]):\n",
    "        conf_mat[labels[i], outputs[i]] += 1\n",
    "\n",
    "# Make each row sum to 1\n",
    "for i in range(conf_mat.shape[0]):\n",
    "    conf_mat[i] = conf_mat[i] / np.sum(conf_mat[i])\n",
    "\n",
    "figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, xticklabels=sig_names, yticklabels=sig_names, fmt='.2f')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('RFE Fused Model Confusion Matrix')\n",
    "plt.savefig('../data/fusion_plots/confusion_matrices/rfe_confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be4f93-185b-4cd8-8f28-4e1fffa98be5",
   "metadata": {},
   "source": [
    "## Get accuracy and confusion matrices for individual teams' models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e081d-4c72-4332-a8a4-5363bc1891d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Team 1\n",
    "# Get model predictions\n",
    "outputs = []\n",
    "with torch.inference_mode():\n",
    "    for idx, inputs in tqdm(enumerate(team1_validation_dataloader)):\n",
    "        pred = np.argmax(team1_model(inputs.to(device)).cpu())\n",
    "        outputs.append(pred)\n",
    "outputs = np.array(outputs)\n",
    "print(outputs.shape)\n",
    "# Create the confusion matrix\n",
    "conf_mat = np.zeros((num_classes, num_classes))\n",
    "for i in range(outputs.shape[0]):\n",
    "    conf_mat[labels[i], outputs[i]] += 1\n",
    "    \n",
    "\n",
    "# Make each row in the confusion matrix sum to 1\n",
    "for i in range(conf_mat.shape[0]):\n",
    "    conf_mat[i] = conf_mat[i] / np.sum(conf_mat[i])\n",
    "\n",
    "# Get the overall accuracy\n",
    "num_correct = np.sum(outputs == labels)\n",
    "accuracy = num_correct / len(outputs)\n",
    "print('Team 1 model validation accuracy:', accuracy)\n",
    "\n",
    "# Set up plot\n",
    "figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, xticklabels=sig_names, yticklabels=sig_names, fmt='.2f')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Team 1 Model Confusion Matrix')\n",
    "plt.savefig('../data/fusion_plots/confusion_matrices/team1_confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f92ed-ab06-4ea3-a2c8-41963fac12e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Team 2\n",
    "# Get model predictions\n",
    "outputs = []\n",
    "with torch.inference_mode():\n",
    "    for idx, inputs in tqdm(enumerate(team2_validation_dataloader)):\n",
    "        pred = np.argmax(team2_model(inputs.to(device)).cpu())\n",
    "        outputs.append(pred)\n",
    "outputs = np.array(outputs)\n",
    "\n",
    "# Create the confusion matrix\n",
    "conf_mat = np.zeros((num_classes, num_classes))\n",
    "for i in range(outputs.shape[0]):\n",
    "    conf_mat[labels[i], outputs[i]] += 1\n",
    "\n",
    "# Make each row in the confusion matrix sum to 1\n",
    "for i in range(conf_mat.shape[0]):\n",
    "    conf_mat[i] = conf_mat[i] / np.sum(conf_mat[i])\n",
    "\n",
    "# Get the overall accuracy\n",
    "num_correct = np.sum(outputs == labels)\n",
    "accuracy = num_correct / len(outputs)\n",
    "print('Team 2 model validation accuracy:', accuracy)\n",
    "\n",
    "# Set up plot\n",
    "figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, xticklabels=sig_names, yticklabels=sig_names, fmt='.2f')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Team 2 Model Confusion Matrix')\n",
    "plt.savefig('../data/fusion_plots/confusion_matrices/team2_confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa0939b-2208-43d0-9bc3-aec1c146aa2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Team 3\n",
    "# Get model predictions\n",
    "outputs = []\n",
    "with torch.inference_mode():\n",
    "    for idx, inputs in tqdm(enumerate(team3_validation_dataloader)):\n",
    "        pred = np.argmax(team3_model(inputs.to(device)).cpu())\n",
    "        outputs.append(pred)\n",
    "outputs = np.array(outputs)\n",
    "\n",
    "# Create the confusion matrix\n",
    "conf_mat = np.zeros((num_classes, num_classes))\n",
    "for i in range(outputs.shape[0]):\n",
    "    conf_mat[labels[i], outputs[i]] += 1\n",
    "\n",
    "# Make each row in the confusion matrix sum to 1\n",
    "for i in range(conf_mat.shape[0]):\n",
    "    conf_mat[i] = conf_mat[i] / np.sum(conf_mat[i])\n",
    "\n",
    "# Get the overall accuracy\n",
    "num_correct = np.sum(outputs == labels)\n",
    "accuracy = num_correct / len(outputs)\n",
    "print('Team 3 model validation accuracy:', accuracy)\n",
    "\n",
    "# Set up plot\n",
    "figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, xticklabels=sig_names, yticklabels=sig_names, fmt='.2f')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Team 3 Model Confusion Matrix')\n",
    "plt.savefig('../data/fusion_plots/confusion_matrices/team3_confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d37691-a555-4a3f-b27f-b2048ab84503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Team 4\n",
    "# Get model predictions\n",
    "outputs = []\n",
    "with torch.inference_mode():\n",
    "    for idx, inputs in tqdm(enumerate(team4_validation_dataloader)):\n",
    "        pred = np.argmax(team4_model(inputs.to(device)).cpu())\n",
    "        outputs.append(pred)\n",
    "outputs = np.array(outputs)\n",
    "\n",
    "# Create the confusion matrix\n",
    "conf_mat = np.zeros((num_classes, num_classes))\n",
    "for i in range(outputs.shape[0]):\n",
    "    conf_mat[labels[i], outputs[i]] += 1\n",
    "\n",
    "# Make each row in the confusion matrix sum to 1\n",
    "for i in range(conf_mat.shape[0]):\n",
    "    conf_mat[i] = conf_mat[i] / np.sum(conf_mat[i])\n",
    "\n",
    "# Get the overall accuracy\n",
    "num_correct = np.sum(outputs == labels)\n",
    "accuracy = num_correct / len(outputs)\n",
    "print('Team 4 model validation accuracy:', accuracy)\n",
    "\n",
    "# Set up plot\n",
    "figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, xticklabels=sig_names, yticklabels=sig_names, fmt='.2f')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Team 4 Model Confusion Matrix')\n",
    "plt.savefig('../data/fusion_plots/confusion_matrices/team4_confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d6a46-af59-4893-adc9-0d5790b5ae27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.13-cpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
